{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66352e43-fdc9-4a1b-acfb-6f8f92e4ffc6",
   "metadata": {},
   "source": [
    "# Oslo Bike Share System Analysis  \n",
    "*Insights from geography, network structure, and time-based patterns*  \n",
    "  \n",
    "Oslo's bike-sharing system **Bysykkel** is a popular and practical way to get around the city. As a frequent user, I noticed how bikes often accumulate downtown, and that pattern sparked my curiosity. Since Bysykkel publishes historical ride data, I set out to explore what these data could reveal. In this project, I investigate how **topography, network structure**, and **temporal patterns** influence the system, and what it takes to keep it balanced and useful.\n",
    "\n",
    "## Project overview\n",
    "**Data Source:** [Oslo Bysykkel Historical Data](https://oslobysykkel.no/apne-data/historisk) (using all data from **2024**)  \n",
    "  \n",
    "This dataset contains records of all historical bysykkel rides in 2024. Each row represents one ride and includes details on start and end stations, timestamps, and coordinates. The analysis is structured in three phases:\n",
    "1. **Topographical flow analysis**  \n",
    "2. **Network structure analysis**  \n",
    "3. **Temporal pattern analysis**\n",
    "\n",
    "## Key questions\n",
    "1. **How does topography affect the flow of bikes?**  \n",
    "2. **Which stations are most important to the network?**  \n",
    "3. **What are the most popular routes?**  \n",
    "4. **What temporal patterns are hidden in the data?**  \n",
    "\n",
    "## Key findings\n",
    "- Oslo's elevation profile causes a **consistent flow of bikes downhill** toward the city center. Cyclists tend to roll downtown but often return home by other means. This creates predictable station imbalances. \n",
    "- A **handful of key stations** act as major import hubs in the city center and export hubs in the outskirts. These are critical to the system's overall balance.  \n",
    "- Bike flow changes throughout the day. Stations follow distinct usage patterns and can be categorized as **importers, exporters, or balanced**.  \n",
    "- **Weekday usage dominates.** Bysykkel is used more as a commuting tool than for leisurely weekend rides.  \n",
    "  \n",
    "These insights help reveal the system's hidden structure, and the invisible work required to keep it operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import glob\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import math\n",
    "\n",
    "# Global parameters\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'axes.labelsize': 11,\n",
    "    'grid.alpha': 0.3,\n",
    "})\n",
    "\n",
    "# Folium parameters\n",
    "oslo_coordinates = [59.92381785337289, 10.746284281064217]\n",
    "zoom = 14.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c610395",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "The first step of the project is to get familiar with the dataset in order to find data quality issues. The findings will be used to decide which cleaning steps will be needed.  \n",
    " \n",
    "### 1.1 Loading the data\n",
    "This step reads all monthly CSV files from the `../data/` folder and loads them into a DuckDB database file (`db/bysykkel_2024.duckdb`). If the database doesn't exist, it will be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSVs into DuckDB table 'trips_raw'\n",
    "con = duckdb.connect(\"../db/bysykkel_2024.duckdb\")\n",
    "\n",
    "# csv_files = glob.glob(\"../data/??.csv\")\n",
    "# for i, file in enumerate(csv_files):\n",
    "#     if i == 0:\n",
    "#         con.execute(f\"CREATE OR REPLACE TABLE trips_raw AS SELECT * FROM read_csv_auto('{file}')\")\n",
    "#     else:\n",
    "#         con.execute(f\"INSERT INTO trips_raw SELECT * FROM read_csv_auto('{file}')\")\n",
    "\n",
    "# con.execute(\"CHECKPOINT\")\n",
    "# print(\"Loaded trips_raw data into DuckDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896a7df",
   "metadata": {},
   "source": [
    "### 1.2 Exploring dataset and columns\n",
    "Let's explore column by column and see what's going on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d50a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = con.execute('SELECT * FROM trips_raw').df()\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbb9732",
   "metadata": {},
   "source": [
    "The dataset contains 13 columns, where each column represents one ride. Only the `start_station_description`and the `end_station_description` contain null values. These columns contain no value to the project and will be discarded.  \n",
    "  \n",
    "> ❗ Drop start_station_description and end_station_description columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6b0447",
   "metadata": {},
   "source": [
    "#### 1.2.1 Columns `started_at` & `ended_at`\n",
    "These columns state the times at which a ride was started and ended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d67fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Check if ended_at is always after started_at\n",
    "(trips['ended_at'] >= trips['started_at']).all()\n",
    "print(f\"Are all return times after the trip was started? {(trips['ended_at'] >= trips['started_at']).all()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbda590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot usage frequency\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Group by day\n",
    "daily = trips.groupby(trips['started_at'].dt.date).size()\n",
    "\n",
    "# Convert index to datetime (from date)\n",
    "daily.index = pd.to_datetime(daily.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(daily.index, daily.values, color='steelblue', linewidth=1.5)\n",
    "\n",
    "# Format x-axis with months\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "plt.title(\"Daily bike usage throughout 2024\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of daily rides\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/daily_ride_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802298e0",
   "metadata": {},
   "source": [
    "✅ No problems detected in this column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10326732",
   "metadata": {},
   "source": [
    "#### 1.2.2 Column `duration`\n",
    "The `duration` column states the duration of the ride in seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot duration distribution, log scale helps\n",
    "plt.figure()\n",
    "sns.histplot(data=trips, x='duration', bins=100, log_scale=True)\n",
    "plt.title(\"Ride duration\")\n",
    "plt.xlabel(\"Ride duration [sec]\")\n",
    "plt.axvline(7200, c='grey', linewidth=0.5, linestyle='--', label=\"2h\")\n",
    "plt.legend(frameon=False)\n",
    "plt.ylabel(\"Number of rides\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "There are {(trips[trips['duration']>7200]).size:,.0f} rides that exceed 2 hours.\\nIt is likely that these are not actual rides but bikes that were unsuccessfully returned. These will be removed from the dataset.  \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba57aaa",
   "metadata": {},
   "source": [
    "✅ No missing values.  \n",
    "❗ Remove rides longer than 2 hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6d685",
   "metadata": {},
   "source": [
    "#### 1.2.3 Columns `start_station_id` & `end_station_id`\n",
    "These columns state a unique id for each station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35319b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of start stations: {len(set(trips['start_station_id']))}\")\n",
    "print(f\"Number of end stations: {len(set(trips['end_station_id']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ids = set(trips['start_station_id'].unique())\n",
    "end_ids = set(trips['end_station_id'].unique())\n",
    "\n",
    "only_start = start_ids - end_ids\n",
    "only_end = end_ids - start_ids\n",
    "\n",
    "print(f\"Start-only stations: {len(only_start)}\")\n",
    "print(f\"End-only stations: {len(only_end)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7867546",
   "metadata": {},
   "source": [
    "Check how many trips are **loops**, so trips where the start and end stations are identical. These might distort the picture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5978b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(trips[trips['start_station_id']==trips['end_station_id']]):,.0f} trips with identical start and end point. These will be discarded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970454f6",
   "metadata": {},
   "source": [
    "✅ No missing values.  \n",
    "❗ Remove loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40c4cc",
   "metadata": {},
   "source": [
    "#### 1.2.3 Columns `start_station_name` & `end_station_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bca24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of start stations: {len(set(trips['start_station_name']))}\")\n",
    "print(f\"Number of start stations: {len(set(trips['end_station_name']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e23a4c",
   "metadata": {},
   "source": [
    "There are two more unique station names than station id's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_names = set(trips['start_station_name'].unique())\n",
    "end_names = set(trips['end_station_name'].unique())\n",
    "\n",
    "only_start_names = start_names - end_names\n",
    "only_end_names = end_names - start_names\n",
    "\n",
    "print(f\"Start-only station names: {len(only_start_names)}\")\n",
    "print(f\"End-only station names: {len(only_end_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_name_map = (\n",
    "    trips[['start_station_id', 'start_station_name']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('start_station_id')['start_station_name']\n",
    "    .nunique()\n",
    ")\n",
    "\n",
    "# IDs with >1 unique name\n",
    "inconsistent_ids = start_name_map[start_name_map > 1]\n",
    "print(f\"Start station IDs with multiple names: {len(inconsistent_ids)}\")\n",
    "print(inconsistent_ids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59429188",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_name_map = (\n",
    "    trips[['end_station_id', 'end_station_name']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('end_station_id')['end_station_name']\n",
    "    .nunique()\n",
    ")\n",
    "\n",
    "# IDs with >1 unique name\n",
    "inconsistent_ids = end_name_map[end_name_map > 1]\n",
    "print(f\"End station IDs with multiple names: {len(inconsistent_ids)}\")\n",
    "print(inconsistent_ids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trips[trips['start_station_id']==608]\n",
    "df['start_station_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a58171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trips[trips['start_station_id']==1101]\n",
    "df['start_station_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c700f",
   "metadata": {},
   "source": [
    "❗ **Note:** Stations with IDs **608** and **1101** appear under multiple names. Station ID **608** is listed as both *Colletts gate* and *Diriks gate*, and **1101** as *Stortingstunellen* and *Stortingstunnelen*. These inconsistencies affect about 1% of entries. Use `station_id`as the unique key when creating the station table to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17734cc",
   "metadata": {},
   "source": [
    "#### 1.2.4 Colummns `start_station_latitude`, `end_station_latitude`, `start_station_longitude`, `end_station_longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479458d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "trips['start_station_latitude'].hist(ax=axs[0, 0], bins=50, color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "axs[0, 0].set_title('Start Station Latitude')\n",
    "axs[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "trips['end_station_latitude'].hist(ax=axs[0, 1], bins=50, color='darkseagreen', alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "axs[0, 1].set_title('End Station Latitude')\n",
    "axs[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "trips['start_station_longitude'].hist(ax=axs[1, 0], bins=50, color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "axs[1, 0].set_title('Start Station Longitude')\n",
    "axs[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "trips['end_station_longitude'].hist(ax=axs[1, 1], bins=50, color='darkseagreen', alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "axs[1, 1].set_title('End Station Longitude')\n",
    "axs[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('Coordinate value validation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89800c93",
   "metadata": {},
   "source": [
    "#### Column Audit Summary\n",
    "\n",
    "| Column                      | Notes                                                                 |\n",
    "|-----------------------------|-----------------------------------------------------------------------|\n",
    "| `started_at`, `ended_at`    | ✅ Valid timestamps, no missing values. |\n",
    "| `duration`                  | ⚠️ No missing values, but contains outliers > 2 hours → to be removed in SQL. |\n",
    "| `start_station_id`          | ✅ Valid IDs. However, 30,188 trips are loops (start = end) → to be removed. |\n",
    "| `end_station_id`            | ✅ Valid IDs. Same note as above.                                    |\n",
    "| `start_station_name`        | ⚠️ Mostly consistent. Two IDs (608 and 1101) map to multiple names. Will use the most common. |\n",
    "| `end_station_name`          | ⚠️ Same as above. No major action needed if we trust IDs.            |\n",
    "| `start_station_description` | ❌ Incomplete. Will be dropped in cleaning step.                 |\n",
    "| `end_station_description`   | ❌ Same as above.                                                    |\n",
    "| `start_station_latitude`    | ✅ All values present. Range appears valid.                          |\n",
    "| `end_station_latitude`      | ✅ Same as above.                                                    |\n",
    "| `start_station_longitude`   | ✅ All values present. Range appears valid.                          |\n",
    "| `end_station_longitude`     | ✅ Same as above.                                                    |\n",
    "\n",
    "\n",
    "#### Cleaning actions to apply in SQL\n",
    "\n",
    "- Remove trips longer than 2 hours  \n",
    "- Remove loops (start and end station ID are the same)  \n",
    "- Drop `start_station_description` and `end_station_description`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fdb56",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.3 Cleaning in SQL\n",
    "In this step, the dataset is cleaned and the issues identified druing the exploration phase addressed.\n",
    "\n",
    "The goal is to create two well-structured tables:\n",
    "1. `trips_clean`: A filtered dataset without outliers or irrelevant columns, ready for analysis in pandas.\n",
    "2. `stations`: A normalized table listing all stations in the system, containing consistent names, IDs, and geographic coordinates\n",
    "\n",
    "#### 2.1 Create `trips_clean` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70958a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rides longer than 2 hours (= 7200 sec)\n",
    "# Remove loops\n",
    "# Drop station descriptions\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE trips_clean AS\n",
    "SELECT \n",
    "    * EXCLUDE (start_station_description, end_station_description)\n",
    "FROM trips_raw\n",
    "WHERE\n",
    "    duration < 7200 AND\n",
    "    start_station_id != end_station_id\n",
    "\"\"\")\n",
    "con.execute(\"CHECKPOINT\")\n",
    "print(\"Cleaned trips saved to DuckDB as 'trips_clean'\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b8ddd",
   "metadata": {},
   "source": [
    "#### 1.4 Create `stations` table by extracting unique stations  \n",
    "Build a `stations` table by combining all distinct start and end stations from the `trips_clean` table. This gives the full list of physical bike stations to enrich with elevation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc295e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE stations AS\n",
    "SELECT DISTINCT\n",
    "    station_id,\n",
    "    station_name,\n",
    "    ROUND(lat, 5) AS lat,\n",
    "    ROUND(lon, 5) AS lon\n",
    "FROM (\n",
    "    SELECT\n",
    "        start_station_id AS station_id,\n",
    "        start_station_name AS station_name,\n",
    "        start_station_latitude AS lat,\n",
    "        start_station_longitude AS lon\n",
    "    FROM trips_clean\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT\n",
    "        end_station_id AS station_id,\n",
    "        end_station_name AS station_name,\n",
    "        end_station_latitude AS lat,\n",
    "        end_station_longitude AS lon\n",
    "    FROM trips_clean\n",
    ")\n",
    "ORDER BY station_id\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"CHECKPOINT\")\n",
    "print(\"Extracted and saved 'stations' table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e0d83",
   "metadata": {},
   "source": [
    "#### 1.5 Summary of cleaning steps\n",
    "After cleaning the dataset we have:\n",
    "- **`trips_clean`**: Filtered dataset\n",
    "    - Removed rides longer than 2 hours and \"loop\" trips that started and ended at the same station.\n",
    "    - Dropped unused station description fields.\n",
    "- **`stations`:** List of all stations in the network\n",
    "    - Extracted all unique stations from both trip endpoints. Will be enriched later (e.g. elevation).  \n",
    "  \n",
    "The dataset is now ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99263f9f",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Phase 1: Topographical flow analysis\n",
    "In this phase of the project, I'll investigate whether Oslo's topography influences bike usage patterns. Oslo has a natural gradient from sea level upwards, which suggests that cyclists might prefer downhill over uphill routes.  \n",
    "\n",
    "**Questions to answer:**\n",
    "1. Do cyclists prefer downhill routes? If so, by what margin?\n",
    "2. How does elevation affect station imbalance?\n",
    "3. Which specific stations require the most urgent daily rebalancing?\n",
    "\n",
    "### 2.1 Enhancing data with elevation information\n",
    "Before analyzing the effect of the terrain, I need to add elevation information based on the geographic location of each bike station in the system. This can easily be achieved using the free api service \"open-meteo.com\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stations table and add elevation data\n",
    "csv_path = \"../db/stations_with_elevation.csv\"\n",
    "\n",
    "def get_elevation(row):\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "    \n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/elevation?latitude={lat}&longitude={lon}\")\n",
    "    data = response.json()\n",
    "    return data['elevation'][0]\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    print(\"Found existing data. Loading from csv.\")\n",
    "    stations = pd.read_csv(csv_path)\n",
    "else:\n",
    "    print(\"No csv found. Fetching elevation data from API.\")\n",
    "    stations = con.execute(\"SELECT * FROM stations\").df()\n",
    "    stations = stations.drop_duplicates(subset='station_id')\n",
    "    stations['elevation'] = stations.apply(get_elevation, axis=1)\n",
    "    stations.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"Elevation received for all stations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save elevation data to database\n",
    "con.register(\"stations_df\", stations)\n",
    "con.execute(\"CREATE OR REPLACE TABLE stations AS SELECT * FROM stations_df\")\n",
    "con.unregister(\"stations_df\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich trips with elevation data (overwriting original)\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE trips_clean AS\n",
    "SELECT\n",
    "    t.*,   \n",
    "    s_start.elevation AS start_elevation,\n",
    "    s_end.elevation AS end_elevation,\n",
    "    s_end.elevation - s_start.elevation AS elevation_diff\n",
    "FROM trips_clean t\n",
    "JOIN stations s_start ON t.start_station_id = s_start.station_id\n",
    "JOIN stations s_end ON t.end_station_id = s_end.station_id\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"CHECKPOINT\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78330ed",
   "metadata": {},
   "source": [
    "#### Loading Analysis-Ready Data into pandas\n",
    "Now that the data has been cleaned and enriched with elevation information, it is ready to be loaded into pandas for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enriched data into pandas for analysis\n",
    "con = duckdb.connect(\"../db/bysykkel_2024.duckdb\")\n",
    "trips = con.execute(\"SELECT * FROM trips_clean\").df()\n",
    "stations = con.execute(\"SELECT * FROM stations\").df()\n",
    "con.close()\n",
    "\n",
    "print(f\"Loaded {len(trips):,} clean trips and {len(stations)} stations\")\n",
    "print(f\"Data spans from {trips['started_at'].min()} to {trips['started_at'].max()}\")\n",
    "\n",
    "# Quick check of our elevation data\n",
    "print(f\"\\nElevation range: {stations['elevation'].min():.1f}m to {stations['elevation'].max():.1f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bf76c",
   "metadata": {},
   "source": [
    "### 2.2 Grouping stations\n",
    "Some bike stations in Oslo are placed extremely close together, sometimes just across the road or even side by side. In practice, these stations act as one single hub, which is why I am manually grouping them into station clusters to get a clearer view of bike flows. This will reduce visual clutter when visualizing the network later, and it will be easier to make out where the hotspots are.  \n",
    "\n",
    "After grouping:\n",
    "-  A the `stations` table is updated to consolidate selected clusters. Coordinates are replaced by the average (centroid) of grouped locations. \n",
    "- The `trips` table is updated to reflect the new grouped station IDs and coordinates. \n",
    "- \"Loop\" rides (trips starting and ending at the same station) are removed again since grouping may have introduced new ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a734ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_groups = {\n",
    "    'Tjuvholmen': [534, 479],\n",
    "    'Aker Brygge': [1755, 2358, 558, 2357],\n",
    "    'Vippetangen': [452, 441],\n",
    "    'Oslo S': [443, 392, 599],\n",
    "    'Jernbanetorget': [478, 2328], \n",
    "    'Torggata': [437, 489],\n",
    "    'Alexander Kiellands Plass': [421, 444, 617],\n",
    "    'Arkaden': [545, 577],\n",
    "    'Brugata / Vaterlandsparken': [491, 495],\n",
    "    'Schous Plass': [401, 423, 463],\n",
    "\n",
    "}\n",
    "\n",
    "# Create mapping of old ID to new ID\n",
    "id_mapping = {}\n",
    "for group_name, station_ids in station_groups.items():\n",
    "    new_id = station_ids[0] # Use first id for all stations in the group\n",
    "    for id in station_ids:\n",
    "        id_mapping[id] = new_id\n",
    "\n",
    "\n",
    "# Create grouped dataframe\n",
    "stations_grouped = []\n",
    "\n",
    "for group_name, station_ids in station_groups.items():\n",
    "    station_cluster = stations[stations['station_id'].isin(station_ids)]\n",
    "    stations_grouped.append({\n",
    "        'station_id': station_ids[0],\n",
    "        'station_name': group_name,\n",
    "        'lat': station_cluster['lat'].mean(),\n",
    "        'lon': station_cluster['lon'].mean(),\n",
    "        'elevation': station_cluster['elevation'].mean()\n",
    "        \n",
    "    })\n",
    "\n",
    "\n",
    "# all_grouped_ids = []\n",
    "# for _, ids in station_groups.items():\n",
    "#     for id in ids:\n",
    "#         all_grouped_ids.append(id)\n",
    "all_grouped_ids = [id for ids in station_groups.values() for id in ids]\n",
    "ungrouped_stations = stations[~stations['station_id'].isin(all_grouped_ids)]\n",
    "\n",
    "for _, station in ungrouped_stations.iterrows():\n",
    "    stations_grouped.append({\n",
    "        'station_id': station['station_id'],\n",
    "        'station_name': station['station_name'],\n",
    "        'lat': station['lat'],\n",
    "        'lon': station['lon'],\n",
    "        'elevation': station['elevation']\n",
    "    })\n",
    "stations = pd.DataFrame(stations_grouped)\n",
    "\n",
    "# Create lookup tables\n",
    "name_lookup = stations.set_index('station_id')['station_name'].to_dict()\n",
    "lat_lookup = stations.set_index('station_id')['lat'].to_dict()\n",
    "lon_lookup = stations.set_index('station_id')['lon'].to_dict()\n",
    "\n",
    "\n",
    "\n",
    "trips['start_station_id'] = trips['start_station_id'].map(lambda x: id_mapping.get(x, x))\n",
    "trips['end_station_id'] = trips['end_station_id'].map(lambda x: id_mapping.get(x, x))\n",
    "\n",
    "trips['start_station_name'] = trips['start_station_id'].map(name_lookup)\n",
    "trips['end_station_name'] = trips['end_station_id'].map(name_lookup)\n",
    "trips['start_station_latitude'] = trips['start_station_id'].map(lat_lookup)\n",
    "trips['start_station_longitude'] = trips['start_station_id'].map(lon_lookup)\n",
    "trips['end_station_latitude'] = trips['end_station_id'].map(lat_lookup)\n",
    "trips['end_station_longitude'] = trips['end_station_id'].map(lon_lookup)\n",
    "\n",
    "# Remove loops\n",
    "trips = trips[trips['start_station_id']!=trips['end_station_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32671b",
   "metadata": {},
   "source": [
    "### 2.2 Calculating trip distance and gradient\n",
    "To understand cyclist preferences, two metrics are calculated for each trip:  \n",
    "  \n",
    "- **Distance**: The physical distance between start and end stations using the haversine formula\n",
    "- **Gradient**: The slope percentage (elevation change divided by distance)  \n",
    "  \n",
    "Using these metrics, each trip can be categorized as uphill, downhill, or flat. This helps analyze route preferences and quantify any bias toward downhill travel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute travel distance and gradient\n",
    "\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "def compute_distance(row):\n",
    "    start = (row['start_station_latitude'], row['start_station_longitude'])\n",
    "    end = (row['end_station_latitude'], row['end_station_longitude'])\n",
    "    return haversine(start, end, unit=Unit.METERS)\n",
    "\n",
    "trips[\"distance\"] = trips.apply(compute_distance, axis=1)\n",
    "\n",
    "def compute_gradient(row):\n",
    "    if row['distance'] == 0:\n",
    "        return np.nan\n",
    "    return row['elevation_diff'] / row['distance'] * 100\n",
    "\n",
    "trips[\"gradient\"] = trips.apply(compute_gradient, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b69edc",
   "metadata": {},
   "source": [
    "### 2.3 Do cyclists prefer downhill routes?\n",
    "Now we're ready to analyze whether there's a preference for downhill vs. uphill travel.\n",
    "\n",
    "#### 2.3.1 Gradient distribution analysis\n",
    "To understand the overall terrain preferences, we'll first examine the distribution of trip gradients across all rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of trip gradients\n",
    "plt.figure()\n",
    "n, bins, patches = plt.hist(trips[\"gradient\"], \n",
    "                            bins=200, \n",
    "                            edgecolor=\"black\", alpha=0.7, linewidth=0.2)\n",
    "\n",
    "for i, patch in enumerate(patches):\n",
    "    if bins[i] < 0:\n",
    "        patch.set_facecolor(\"green\")\n",
    "    elif bins[i] > 0:\n",
    "        patch.set_facecolor(\"brown\")\n",
    "    else:\n",
    "        patch.set_facecolor(\"grey\")\n",
    "\n",
    "plt.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.7)\n",
    "plt.xlim([-10, 10])\n",
    "plt.title(\"Gradient distribution\")\n",
    "plt.xlabel(\"Gradient [%]\")\n",
    "plt.ylabel(\"Frequency of rides\")\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"green\", label=\"downhill\"),\n",
    "    Patch(facecolor=\"grey\", label=\"flat\"),\n",
    "    Patch(facecolor=\"brown\", label=\"uphill\")\n",
    "]\n",
    "plt.legend(handles=legend_elements)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient stats\n",
    "median_gradient = trips[\"gradient\"].mean()\n",
    "n_uphill = len(trips[trips['gradient']>0])\n",
    "n_downhill = len(trips[trips['gradient']<0])\n",
    "n_flat = len(trips[trips['gradient']==0])\n",
    "n_total = len(trips)\n",
    "\n",
    "percent_uphill = n_uphill / n_total * 100\n",
    "percent_downhill = n_downhill / n_total * 100\n",
    "percent_flat = n_flat / n_total * 100\n",
    "net_bias = (n_downhill - n_uphill) / n_total * 100\n",
    "relative_increase = (n_downhill - n_uphill) / n_uphill * 100\n",
    "\n",
    "summary = f\"\"\"\n",
    "gradient median = {median_gradient:.2f}%\n",
    "downhill trips: {percent_downhill:.1f}%\n",
    "uphill trips: {percent_uphill:.1f}%\n",
    "flat trips: {percent_flat:.1f}%\n",
    "net bias towards downhill: {net_bias:.1f}%\n",
    "relative increase: {relative_increase:.1f}%\n",
    "\"\"\"\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d734000",
   "metadata": {},
   "source": [
    "Looking at the histogram and the statistics, there are several key patterns in Oslo's bike sharing usage:  \n",
    "  \n",
    "**Visual observations:**  \n",
    "- Downhill rides (negative gradients) are clearly more frequent than uphill rides.  \n",
    "- There's a pronounced spike at gradient 0%, which likely represents popular rides along the flat waterfront paths.\n",
    "- The distribution shows a clear skew towards negative gradients. This indicates a preference for downhill travel. \n",
    "  \n",
    "**Metrics:**\n",
    "Computing the metrics of all trips reveals the following results:\n",
    "- **Downhill trips**: 59.6% of all rides (gradient < 0%)\n",
    "- **Uphill trips**: 38.8% of all rides (gradient > 0%) \n",
    "- **Flat trips**: 1.6% of all rides (gradient = 0%)\n",
    "- **Mean gradient**: -0.44% (indicating an overall downhill bias)  \n",
    "  \n",
    "The data shows that **downhill trips are 53% more common than uphill trips** (59.5% vs. 38.8%). This confirms a strong preference for downhill routes with important implications for bike rebalancing efforts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b68a97",
   "metadata": {},
   "source": [
    "#### 2.3.2 Distance and Duration Analysis\n",
    "Counting uphill vs. downhill trips alone might be misleading. Another interesting detail to look into is how much total distance and time cyclists spend going uphill vs. downhill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5cf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for the slope type\n",
    "def categorize_slope(slope):\n",
    "    if slope < 0:\n",
    "        return \"downhill\"\n",
    "    elif slope > 0:\n",
    "        return \"uphill\"\n",
    "    else:\n",
    "        return \"flat\"\n",
    "    \n",
    "trips['slope_type'] = trips['gradient'].apply(categorize_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(6,10))\n",
    "\n",
    "# Duration histogram\n",
    "sns.histplot(data=trips, x='duration', hue='slope_type', \n",
    "             hue_order=['flat', 'uphill', 'downhill'], \n",
    "             bins=50, kde=True, log_scale=True, ax=ax1, legend=True,\n",
    "             palette=['lightblue', 'salmon', 'green'])\n",
    "ax1.set_title(\"Trip duration by gradient direction\")\n",
    "ax1.set_xlabel(\"Duration [s]\")\n",
    "ax1.set_ylabel(\"Frequency of rides\")\n",
    "ax1.legend(title=\"\", labels=[\"flat\", \"uphill\", \"downhill\"])\n",
    "\n",
    "\n",
    "# Distance histogram  \n",
    "sns.histplot(data=trips, x='distance', hue='slope_type',\n",
    "             hue_order=['flat', 'uphill', 'downhill'], \n",
    "             bins=80, kde=True, log_scale=True, ax=ax2, legend=True,\n",
    "             palette=['lightblue', 'salmon', 'green'])\n",
    "ax2.set_title(\"Trip distance by gradient direction\") \n",
    "ax2.set_xlabel(\"Distance [m]\")\n",
    "ax2.set_ylabel(\"Frequency of rides\")\n",
    "ax2.legend(title=\"\", labels=[\"flat\", \"uphill\", \"downhill\"])\n",
    "plt.xlim([50, 5000])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "usage_summary = trips.groupby('slope_type').agg({\n",
    "    'duration': ['sum', 'mean', 'count'],\n",
    "    'distance': ['sum', 'mean']}).round(1)\n",
    "usage_summary.columns = ['Total duration [s]', 'Average duration [s]', 'Number of rides', 'Total distance [m]', 'Average distance [m]']\n",
    "print(usage_summary.to_string())\n",
    "\n",
    "# Calculate comparisons (downhill vs. uphill)\n",
    "duration_up = usage_summary.loc['uphill', 'Total duration [s]']\n",
    "duration_down = usage_summary.loc['downhill', 'Total duration [s]']\n",
    "distance_up = usage_summary.loc['uphill', 'Total distance [m]']\n",
    "distance_down = usage_summary.loc['downhill', 'Total distance [m]']\n",
    "\n",
    "# Calculate percentage differences\n",
    "duration_diff_pct = (duration_down - duration_up) / duration_up * 100\n",
    "distance_diff_pct = (distance_down - distance_up) / distance_up * 100\n",
    "\n",
    "# Per-trip comparison\n",
    "avg_duration_up = usage_summary.loc['uphill', 'Average duration [s]']\n",
    "avg_duration_down = usage_summary.loc['downhill', 'Average duration [s]']\n",
    "avg_distance_up = usage_summary.loc['uphill', 'Average distance [m]']\n",
    "avg_distance_down = usage_summary.loc['downhill', 'Average distance [m]']\n",
    "\n",
    "time_per_trip_diff = (avg_duration_down - avg_duration_up) / avg_duration_down * 100\n",
    "distance_per_trip_diff = (avg_distance_down - avg_distance_up) / avg_distance_up * 100\n",
    "\n",
    "print(\"\\nKey Comparisons\")\n",
    "print(f\"\"\"\n",
    "      - Downhill trips account for {duration_diff_pct:.1f}% more total ride time.\n",
    "      - Downhill trips cover {distance_diff_pct:.1f}% more total distance.\n",
    "      - Uphill trips take on average {abs(time_per_trip_diff):.1f}% longer per trip.\n",
    "      - Downhill trips cover {distance_per_trip_diff:.1f}% more distance per trip.\n",
    "      \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3e999",
   "metadata": {},
   "source": [
    "#### 2.3.3 Summary: Evidence of downhill preference\n",
    "This analysis provides strong evidence that cyclists prefer downhill routes accross multiple metrics:\n",
    "\n",
    "**Trip distribution:**\n",
    "- 59.6% of trips go downhill vs. 38.8% go uphill (53% more common).\n",
    "- Mean gradient of -0.44 indicates overall bias towards downhill travel.\n",
    "\n",
    "**Total system usage:**\n",
    "- Downhill trips account for 37.7% more total ride time.\n",
    "- Downhill trips cover 68.2% more total distance.\n",
    "\n",
    "**Individual trip properties:**\n",
    "- Uphill trips take on average 11.4% longer.\n",
    "- Downhill trips cover on average 9.7% more distance.\n",
    "\n",
    "**Answer to question 1:** Yes, cyclists show a strong preference towards downhill routes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d988fcad",
   "metadata": {},
   "source": [
    "### 2.4 How does elevation affect station imbalance?\n",
    "\n",
    "Having established that customers have a strong preference for downhill trips, it is now time to investigate how that affects the net flow of bikes.  \n",
    "\n",
    "#### 2.4.1 Compute net flux per station\n",
    "I will start out by computing the **net flux** per station:  \n",
    "```\n",
    "net flux = arriving bikes - departing bikes\n",
    "```\n",
    "This metric shows whether a station tends to accumulate or lose bikes over time. A station with a negative net flux is consistntly losing bikes and acts as an **exporter**, while a positive net flux indicates it acts as an **importer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the net flux per station\n",
    "flux_out = trips.groupby('start_station_id').size().rename('departures')\n",
    "flux_in = trips.groupby('end_station_id').size().rename('arrivals')\n",
    "\n",
    "station_flux = flux_out.to_frame().join(flux_in.to_frame(), how='outer').fillna(0)\n",
    "station_flux['net_flux'] = station_flux['arrivals'] - station_flux['departures']\n",
    "station_flux['total_usage'] = station_flux['arrivals'] + station_flux['departures']\n",
    "station_flux['net_flux_daily'] = station_flux['net_flux'] / 365\n",
    "station_flux['total_usage_daily'] = station_flux['total_usage'] / 365\n",
    "station_flux['departure_share'] = station_flux['departures'] / station_flux['total_usage']\n",
    "\n",
    "station_flux = stations.join(station_flux, how=\"outer\", on=\"station_id\").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96d58b",
   "metadata": {},
   "source": [
    "#### 2.4.2 Elevation's impact on station balance\n",
    "Now we can explore whether elevation plays a key role in determining whether a station tends to **import** or **export** bikes. To do this, we'll plot each station's **net flux** against its **elevation** and look for patterns in the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = plt.scatter(station_flux['elevation'], station_flux['net_flux_daily'],\n",
    "                      c=station_flux['total_usage_daily'],\n",
    "                      s=60, alpha=0.7, cmap='RdYlBu_r',\n",
    "                      edgecolors='black', linewidths=0.5)\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Total station usage', rotation=270, labelpad=15)\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=2, alpha=0.8)\n",
    "plt.axvline(35, color='orange', linestyle=':', linewidth=2, alpha=0.8, label='Elevation threshold (~35m)')\n",
    "\n",
    "plt.xlabel('Elevation [m]')\n",
    "plt.ylabel('Net flux per day (arrivals - departures)')\n",
    "plt.title('Station imbalance vs. elevation')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e34214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The correlation between elevation and net flux is {station_flux['elevation'].corr(station_flux['net_flux']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f570f08",
   "metadata": {},
   "source": [
    "This figure clearly demonstrates how elevation causes station imbalances in Oslo's bike sharing system.  \n",
    "\n",
    "**Key observations:**\n",
    "- **Above ~35m elevation**: Stations predominantly export bikes (negative net flux), losing around 5 to 10 bikes per day.\n",
    "- **Below ~35m elevation**: Stations predominantly import bikes (positive net flux), gaining up to 20 bikes per day. \n",
    "- **Correlation**: The relationship shows a correlation of -0.55, indicating a moderately strong relationship between elevation and station balance.\n",
    "\n",
    "**Operational interpretation:**  \n",
    "Bikes naturally \"flow\" downhill through the system and preferentially accumulate near sea level. This creates a systematic daily imbalance, where:\n",
    "- Higer elevation stations consistently need bike restocking.\n",
    "- Lower elevation stations consistenly need bikes removed to create docking space.\n",
    "- The ~35m elevation mark represents a \"watershed\" for bike flow in the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce37387",
   "metadata": {},
   "source": [
    "#### 2.4.3 Geographic distribution of imbalances\n",
    "Having established that there's a strong relation between elevation and station imbalance, let's now visualize these imbalances on a map.  \n",
    "  \n",
    "  The interactive map below shows all bike stations with:  \n",
    "  - **Marker size**: Proportional to total daily usage (larger circles = busier station)\n",
    "  - **Marker color**: Indicates imbalance of the station and magnitude\n",
    "    - **Red stations**: Net exporters (lose bikes daily, need restocking)\n",
    "    - **Green stations**: Net importers (gain bkes daily, need bike removal)\n",
    "    - **Color intensity**: Darker colors indicate larger daily imbalances  \n",
    "\n",
    "This visualization shows the geographic pattern of Oslo's bike flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d139e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 exporters and importers\n",
    "top_exporters = station_flux.nsmallest(10, 'net_flux_daily')\n",
    "top_importers = station_flux.nlargest(10, 'net_flux_daily')\n",
    "critical_ids = set(top_exporters['station_id'].tolist() + top_importers['station_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10291c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive Folium map of Oslo to spatially demonstrate the behaviour where bikes are flowing\n",
    "\n",
    "def get_color(flux_value):\n",
    "    if flux_value > 2.7:\n",
    "        return '#1a9850'     # Dark green - Heavy importer\n",
    "    elif flux_value > 0.5:\n",
    "        return 'yellowgreen' # Light green - Light importer  \n",
    "    elif flux_value >= -0.5:\n",
    "        return 'gray'        # Gray - Balanced (±0.5 bikes/day)\n",
    "    elif flux_value > -2.7:\n",
    "        return '#fc8d59'     # Orange - Light exporter\n",
    "    else:\n",
    "        return '#d73027'     # Red - Heavy exporter\n",
    "    \n",
    "def get_radius(total_usage):\n",
    "    # Normalize usage\n",
    "    return np.interp(total_usage,\n",
    "                     (station_flux['total_usage_daily'].min(), station_flux['total_usage_daily'].max()),\n",
    "                     (2, 17))\n",
    "\n",
    "flux_map = folium.Map(location=oslo_coordinates, zoom_start=zoom, tiles=\"CartoDB positron\")\n",
    "\n",
    "# First, add all non-critical stations\n",
    "for index, row in station_flux.iterrows():\n",
    "    if row['station_id'] not in critical_ids:  # Only non-critical stations\n",
    "        popup_content = f\"\"\"\n",
    "        Station: {row['station_name']} <br>\n",
    "        ID: {row['station_id']} <br>\n",
    "        Elevation: {row['elevation']:.0f}m <br>\n",
    "        Departures: {row['departures']/365:.0f}/day <br>\n",
    "        Arrivals: {row['arrivals']/365:.0f}/day <br>\n",
    "        Total Usage: {row['total_usage_daily']:.0f}/day <br>\n",
    "        Net Flux: {row['arrivals']/365 - row['departures']/365:+.1f}/day\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add marker\n",
    "        folium.CircleMarker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            radius=get_radius(row['total_usage_daily']),\n",
    "            color=get_color(row['net_flux_daily']),\n",
    "            fill=True,\n",
    "            fill_color=get_color(row['net_flux_daily']),\n",
    "            fill_opacity=0.8,\n",
    "            weight=1,\n",
    "            popup=folium.Popup(popup_content, max_width=300)\n",
    "        ).add_to(flux_map)\n",
    "\n",
    "# Then add critical stations on top\n",
    "for index, row in station_flux.iterrows():\n",
    "    if row['station_id'] in critical_ids:  # Only critical stations\n",
    "        popup_content = f\"\"\"\n",
    "        <b>⚠️ CRITICAL STATION</b><br>\n",
    "        Station: {row['station_name']} <br>\n",
    "        ID: {row['station_id']} <br>\n",
    "        Elevation: {row['elevation']:.0f}m <br>\n",
    "        Departures: {row['departures']/365:.0f}/day <br>\n",
    "        Arrivals: {row['arrivals']/365:.0f}/day <br>\n",
    "        Total Usage: {row['total_usage_daily']:.0f}/day <br>\n",
    "        <b>Net Flux: {row['arrivals']/365 - row['departures']/365:+.1f}/day</b>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add marker\n",
    "        folium.CircleMarker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            radius=get_radius(row['total_usage_daily']),\n",
    "            color='black',\n",
    "            fill=True,\n",
    "            fill_color=get_color(row['net_flux_daily']),\n",
    "            fill_opacity=0.9,  # Slightly higher opacity\n",
    "            weight=3,\n",
    "            popup=folium.Popup(popup_content, max_width=300)\n",
    "        ).add_to(flux_map)\n",
    "\n",
    "# Updated legend to include critical stations\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; bottom: 50px; left: 50px; width: 175px; height: 170px; \n",
    "            background-color:white; border:2px solid grey; z-index:9999; \n",
    "            font-size:12px; padding: 8px\">\n",
    "<b>Net Flux</b><br>\n",
    "<span style=\"color:#d73027\">●</span> Heavy Export<br>\n",
    "<span style=\"color:#fc8d59\">●</span> Light Export<br>\n",
    "<span style=\"color:gray\">●</span> Balanced<br>\n",
    "<span style=\"color:yellowgreen\">●</span> Light Import<br>\n",
    "<span style=\"color:#1a9850\">●</span> Heavy Import<br>\n",
    "<hr style=\"margin: 5px 0;\">\n",
    "<b>⚫</b> = Top 10 critical station\n",
    "</div>\n",
    "'''\n",
    "\n",
    "flux_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "flux_map.save('../outputs/oslo_flux_map.html')\n",
    "flux_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31067358",
   "metadata": {},
   "source": [
    "#### 2.4.4 Summary: Geographic imbalace\n",
    "\n",
    "The interactive map above shows the geographic pattern of the imbalanced flow of bikes in the bike sharing system.  \n",
    "\n",
    "**Clear spatial patterns:**\n",
    "- **Northern/outer areas** (higher elevation): Dominated by red stations that consistantly export bikes - *bike sources*\n",
    "- **Central/southern areas** (lower elevation): Dominated by green stations that consistantly import bikes - *bike sinks*\n",
    "- **Intermediate elevation areas**: Most stations are balanced (gray), creating a transition zone between exporter and importer areas - *transition zone*\n",
    "\n",
    "**Geographic \"watershed\":**\n",
    "There is a clear three-zone pattern: a green core of heavy importers, surrounded by gray balanced stations at intermediate elevations, surrounded by red exporter stations at higher elevations. There is a daily flow of bikes from higher elevation down into the city center and lower elevation regions.  \n",
    "\n",
    "**Important note**: This analysis represents a yearly average across all seasons and times of day. The actual rebalancing challenges may be significantly more pronounced during peak times (rush hours, summer months, weekends)  \n",
    "\n",
    "This visualization demonstrates that bike rebalancing in Oslo is not a random maintenance, but follows a clear geographical pattern. \n",
    "\n",
    "**Answer to question 2:** Elevation systematically affects station imbalance by creating predictable daily bike flows from higher to lower elevations, with stations above ~35m consistently exporting bikes while those below consistently import them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b7e76",
   "metadata": {},
   "source": [
    "### 2.5 Which stations require the most urgent daily rebalancing?\n",
    "Now that we've seen how elevation causes imbalances, let's identify the specific stations that create the most critical challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 heavist importer and exporter stations\n",
    "print(\"TOP 10 EXPORTER STATIONS (Need daily restocking)\")\n",
    "print(\"=\"*70)\n",
    "exporters_display = top_exporters[['station_name', 'elevation', 'net_flux_daily', 'total_usage_daily']].copy()\n",
    "exporters_display.columns = ['Station', 'Elevation [m]', 'Bikes lost daily', 'Total daily usage']\n",
    "exporters_display['Bikes lost daily'] = exporters_display['Bikes lost daily'].round(1).abs()\n",
    "exporters_display['Total daily usage'] = exporters_display['Total daily usage'].round(1)\n",
    "print(exporters_display.to_string(index=False))\n",
    "print(f\"\\nTotal daily restocking need: {top_exporters['net_flux_daily'].abs().sum():.0f} bikes\")\n",
    "print(f\"Average elevation: {top_exporters['elevation'].mean():.1f}m\")\n",
    "\n",
    "print(\"\\nTOP 10 IMPORTER STATIONS (Need daily removal)\")\n",
    "print(\"=\"*70)\n",
    "importers_display = top_importers[['station_name', 'elevation', 'net_flux_daily', 'total_usage_daily']].copy()\n",
    "importers_display.columns = ['Station', 'Elevation [m]', 'Bikes gained daily', 'Total daily usage']\n",
    "importers_display['Bikes gained daily'] = importers_display['Bikes gained daily'].round(1)\n",
    "importers_display['Total daily usage'] = importers_display['Total daily usage'].round(1)\n",
    "print(importers_display.to_string(index=False))\n",
    "print(f\"\\nTotal daily removal need: {top_importers['net_flux_daily'].abs().sum():.0f} bikes\")\n",
    "print(f\"Average elevation: {top_importers['elevation'].mean():.1f}m\")\n",
    "\n",
    "# Impact summary\n",
    "total_critical_flux = abs(top_exporters['net_flux_daily'].sum()) + top_importers['net_flux_daily'].sum()\n",
    "pct_of_stations = 20 / len(stations) * 100\n",
    "\n",
    "print(f\"\"\"\n",
    "OPERATIONAL IMPACT:\n",
    "- These 20 stations ({pct_of_stations:.1f}% of network) require moving ~{total_critical_flux:.0f} bikes daily.\n",
    "- Elevation difference between critical exporters and importers: {top_exporters['elevation'].mean() - top_importers['elevation'].mean():.0f}m\n",
    "- This represents the minimum daily rebalancing operation just to maintain these 20 stations. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0a8e8",
   "metadata": {},
   "source": [
    "### 2.6 Summary: Topography's impact on Oslo's bike sharing system\n",
    "\n",
    "Our topographical analysis reveals that Oslo's terrain creates fundamental operational challenges:\n",
    "\n",
    "**Key finding 1: Strong downhill preference**\n",
    "- Cyclists are 53% more likely to choose downhill routes (59.5% vs 38.8% of trips)\n",
    "- Downhill trips cover 68% more total distance and 38% more ride time\n",
    "- This creates a system-wide \"gravity bias\" with a mean gradient of -0.44%\n",
    "\n",
    "**Key finding 2: Elevation-driven station imbalances**\n",
    "- Moderately strong negative correlation (-0.55) between elevation and daily net flux\n",
    "- Critical elevation threshold at ~35m separates bike exporters from importers\n",
    "- Geographic pattern: red (exporter) periphery → gray (balanced) middle → green (importer) core\n",
    "\n",
    "**Key finding 3: Concentrated rebalancing needs**\n",
    "- Top 10 exporters (avg. 54m elevation) lose 75 bikes daily combined\n",
    "- Top 10 importers (avg. 17m elevation) gain 92 bikes daily combined  \n",
    "- Just 7.5% of stations drive the majority of rebalancing requirements\n",
    "  \n",
    "This analysis proves that Oslo's bike rebalancing isn't random maintenance but a predictable daily battle against gravity. The system experiences a continuous \"downhill tide\" requiring strategic intervention:\n",
    "  \n",
    "The topographical analysis has revealed WHERE bikes flow. Next, we'll examine the network structure to understand HOW bikes move through the system and which routes are most critical for connectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004ccf5",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Phase 2: Network structure analysis\n",
    "The previous section clearly showed that Oslo's topography creates a significant flow from higher to lower elevations. The next step is to investigate *how* bikes move through the city. While elevation gives us a general idea of the direction of the flow, this analysis will reveal which exact pathways are most commonly used.  \n",
    "  \n",
    "Network analysis treates the bike sharing system as a complex web of interconnected stations. Each trip creates a weighted link between locations. Using this technique allows us to understand which stations serve as bike magnets, which routes are most popular, and where the areas for bike export and import are located.  \n",
    "  \n",
    "Key questions to answer:  \n",
    "1. Which stations are most important in the network?\n",
    "2. What are the most important pathways for bike travel?\n",
    "3. How is the bike network organized across Oslo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e555c",
   "metadata": {},
   "source": [
    "### 3.1 Building the network graph\n",
    "The first step is to define the network graph where stations are nodes and trips act as weighted edges between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create bidirectional graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add stations as nodes to graph\n",
    "for _, station in stations.iterrows():\n",
    "    G.add_node(station['station_id'],\n",
    "               name=station['station_name'],\n",
    "               lat=station['lat'],\n",
    "               lon=station['lon'],\n",
    "               elevation=station['elevation'])\n",
    "\n",
    "# Add trips between stations as edges, with frequency of route as weight\n",
    "trip_counts = trips.groupby(['start_station_id', 'end_station_id']).size().reset_index(name='weight')\n",
    "trip_counts = trip_counts.sort_values('weight', ascending=False)#.head(100)\n",
    "\n",
    "for _, trip in trip_counts.iterrows():\n",
    "    G.add_edge(trip['start_station_id'],\n",
    "               trip['end_station_id'],\n",
    "               weight=trip['weight'])\n",
    "\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889cf85",
   "metadata": {},
   "source": [
    "### 3.2 Which stations are the most important?\n",
    "To figure out which stations are the most important, we can calculate a few network metrics:  \n",
    "- **PageRank**: Identifies stations that are well-connected to other well-connected stations (\"hubs\"). This metric correlates very well with total station usage. \n",
    "- **Degree centrality**: Counts how many direct connections a station has to other stations. This metric has a wide plateau, since most stations are connected to most others over the course of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906bb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "pagerank = nx.pagerank(G, weight='weight')\n",
    "degree_centrality = dict(G.degree())  # Number of unique connections\n",
    "\n",
    "# Write to stations table\n",
    "station_flux['pagerank'] = station_flux['station_id'].map(pagerank)\n",
    "station_flux['degree_centrality'] = station_flux['station_id'].map(degree_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top n stations\n",
    "n = 10\n",
    "top_pagerank_stations = station_flux.nlargest(n, 'pagerank')\n",
    "top_centrality_stations = station_flux.nlargest(n, 'degree_centrality')\n",
    "print(\"TOP 10 MOST IMPORTANT STATIONS (by PageRank)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (idx, station) in enumerate(top_pagerank_stations.iterrows(), 1):\n",
    "    print(f\"{i:2d}. {station['station_name']}\")\n",
    "    print(f\"    PageRank: {station['pagerank']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33014cae",
   "metadata": {},
   "source": [
    "### 3.3 What are the most critical pathways?\n",
    "Next, let's find out what the most frequent routes through the city are. This can be done by taking all edges from the network graph and sorting them by the number of trips. This gives a list of the top 15 most popular connections between stations. Below are the most popular routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all edges with their weights (trip counts)\n",
    "all_edges = [(start, end, data['weight']) for start, end, data in G.edges(data=True)]\n",
    "\n",
    "# Sort by weight (trip count) descending\n",
    "popular_routes = sorted(all_edges, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Convert to readable format\n",
    "top_routes = []\n",
    "for start, end, weight in popular_routes[:20]:  # Top 20\n",
    "    route_info = {\n",
    "        'from': G.nodes[start]['name'],\n",
    "        'to': G.nodes[end]['name'],\n",
    "        'trip_count': weight,\n",
    "        'from_elevation': G.nodes[start]['elevation'],\n",
    "        'to_elevation': G.nodes[end]['elevation'],\n",
    "        'gradient': 'downhill' if G.nodes[end]['elevation'] < G.nodes[start]['elevation'] else 'uphill'\n",
    "    }\n",
    "    top_routes.append(route_info)\n",
    "\n",
    "# Display as DataFrame\n",
    "routes_df = pd.DataFrame(top_routes)\n",
    "print(\"TOP 15 MOST POPULAR CONNECTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, (idx, route) in enumerate(routes_df.head(15).iterrows(), 1):\n",
    "    print(f\"{i:2d}. {route['from']} ↔ {route['to']}\")\n",
    "    print(f\"    {route['trip_count']:,} trips\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458e8aa",
   "metadata": {},
   "source": [
    "The most popular routes are short rides along the waterfront, connecting popular areas like Aker Brygge, Vippetangen, Tjuvholmen and Oslo S. These rides are most likely leisure-oriented.  \n",
    "  \n",
    "However, these top connections only account for about **1% of all trips** in the dataset. Even though they dominate the ranking by absolute count, they don't represent the typical bike-sharing usage pattern.  \n",
    "  \n",
    "Later in the analysis, we will see that weekday usage, particularly during commuting hours, dominates the overall flow. The system is used for far more than just leisure rides along the waterfront, as the above ranking might suggest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c74a6",
   "metadata": {},
   "source": [
    "### 3.4 How is the bike network organized across Oslo\n",
    "In order to visually inspect the structure of the network, let's visualize it by drawing the top 800 connections and the top 20 most popular stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f777c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oslo bike network: Core vs. feeder stations\n",
    "\n",
    "n_edges = 600\n",
    "network_flux_map = folium.Map(location=oslo_coordinates, zoom_start=zoom, tiles='CartoDB positron')\n",
    "\n",
    "top_edges = sorted(\n",
    "    G.edges(data=True),\n",
    "    key=lambda x: x[2]['weight'],\n",
    "    reverse=True,\n",
    ")[:n_edges]\n",
    "\n",
    "# Compute weights for scaling\n",
    "weights = [w['weight'] for _, _, w in top_edges]\n",
    "min_weight, max_weight = min(weights), max(weights)\n",
    "\n",
    "# Function for scaling valiables\n",
    "def scale(weight, val_min, val_max, scale_min, scale_max):\n",
    "    return np.interp(\n",
    "        weight,\n",
    "        (val_min, val_max),\n",
    "        (scale_min, scale_max)\n",
    "    )\n",
    "\n",
    "# Plot network\n",
    "for start, end, data in top_edges:\n",
    "    lat1, lon1 = G.nodes[start]['lat'], G.nodes[start]['lon']\n",
    "    lat2, lon2 = G.nodes[end]['lat'], G.nodes[end]['lon']\n",
    "    weight = data['weight']\n",
    "    thickness = scale(data['weight'], min_weight, max_weight, 1, 8)\n",
    "\n",
    "    # Thickness and opacity \n",
    "    thickness = 0.5 + (weight / max_weight) * 10\n",
    "    opacity = 0.2 + (weight / max_weight) * 0.3\n",
    "\n",
    "    folium.PolyLine(\n",
    "        locations=[[lat1, lon1], [lat2, lon2]],\n",
    "        weight=thickness,\n",
    "        opacity=opacity,\n",
    "        color='darkblue',\n",
    "    ).add_to(network_flux_map)\n",
    "\n",
    "\n",
    "\n",
    "# Prepare station list\n",
    "# station_flux['pagerank'] = station_flux['station_id'].map(pagerank)\n",
    "\n",
    "# Classify stations\n",
    "def classify_station(net_flux_daily):\n",
    "    if net_flux_daily > 2:\n",
    "        return 'heavy_importer'\n",
    "    elif net_flux_daily > 0.5:\n",
    "        return 'light_importer'\n",
    "    elif net_flux_daily < -2:\n",
    "        return 'heavy_exporter'\n",
    "    elif net_flux_daily < -0.5:\n",
    "        return 'light_exporter'\n",
    "    else:\n",
    "        return 'balanced'\n",
    "    \n",
    "station_flux['station_type'] = station_flux['net_flux_daily'].apply(classify_station)\n",
    "\n",
    "# Find top stations for labelling\n",
    "top_pagerank = station_flux.nlargest(24, 'pagerank')['station_id'].tolist()\n",
    "top_exporters = station_flux.nsmallest(10, 'net_flux_daily')['station_id'].tolist()\n",
    "top_importers = station_flux.nlargest(10, 'net_flux_daily')['station_id'].tolist()\n",
    "\n",
    "stations_to_label = set(top_pagerank + top_exporters + top_importers)\n",
    "\n",
    "# Color mapping\n",
    "color_map = {\n",
    "    'heavy_exporter': '#d73027',\n",
    "    'light_exporter': '#fc8d59',\n",
    "    'balanced': '#ffffbf',\n",
    "    'light_importer': '#91cf60',\n",
    "    'heavy_importer': '#1a9850',\n",
    "}\n",
    "\n",
    "label_css_template = \"\"\"\n",
    "<style>\n",
    ".label-{unique_id} {{\n",
    "    background-color: rgba(255, 255, 255, 0.9);\n",
    "    color: black;\n",
    "    border: 2px solid {label_color};\n",
    "    box-shadow: 2px 2px 2px rgba(0,0,0,0.3);\n",
    "    font-size: 12px;\n",
    "    padding: 1px 3px;\n",
    "    border-radius: 4px;\n",
    "    font-weight: 600;\n",
    "}}\n",
    "\n",
    "/* Kill the tooltip arrow */\n",
    ".label-{unique_id}:before,\n",
    ".label-{unique_id}:after {{\n",
    "    border: none !important;\n",
    "    background: transparent !important;\n",
    "    box-shadow: none !important;\n",
    "    content: none !important;\n",
    "}}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "def get_radius(total_usage):\n",
    "    # Normalize usage\n",
    "    return np.interp(total_usage,\n",
    "                     (station_flux['total_usage_daily'].min(), station_flux['total_usage_daily'].max()),\n",
    "                     (3, 17))\n",
    "\n",
    "for _, station in station_flux.iterrows():\n",
    "    marker_size = get_radius(station['total_usage_daily'])\n",
    "\n",
    "    # Check if station is top exporter or importer\n",
    "    is_top_exporter = station['station_id'] in top_exporters\n",
    "    is_top_importer = station['station_id'] in top_importers\n",
    "\n",
    "    # Define border style for top stations\n",
    "    if is_top_exporter or is_top_importer:\n",
    "        border_weight = 3\n",
    "        border_color = 'black'\n",
    "    else:\n",
    "        border_weight = 1\n",
    "        border_color='darkgray'\n",
    "\n",
    "    # Station color\n",
    "    fill_color = color_map[station['station_type']]\n",
    "\n",
    "    # Create popup\n",
    "    popup_content = f\"\"\"\n",
    "        <b>{station['station_name']}</b><br>\n",
    "        Type: {station['station_type'].replace('_', ' ').title()}<br>\n",
    "        Net Flux: {station['net_flux_daily']:+.1f} bikes/day<br>\n",
    "        Total Usage: {station['total_usage_daily']:.0f} trips/day<br>\n",
    "        Elevation: {station['elevation']:.0f}m\n",
    "    \"\"\"\n",
    "\n",
    "    # Draw station marker\n",
    "    marker = folium.CircleMarker(\n",
    "        location=[station['lat'], station['lon']],\n",
    "        radius=marker_size,\n",
    "        color=border_color,\n",
    "        weight=border_weight,\n",
    "        fillColor=fill_color,\n",
    "        fill=True,\n",
    "        fillOpacity=0.8,\n",
    "        popup=folium.Popup(popup_content, max_width=300)\n",
    "    ).add_to(network_flux_map)\n",
    "\n",
    "    # Add label to important stations\n",
    "    if station['station_id'] in stations_to_label:\n",
    "        if 'exporter' in station['station_type']:\n",
    "            label_color = '#d73027'\n",
    "        elif 'importer' in station['station_type']:\n",
    "            label_color = '#1a9850'\n",
    "        else:\n",
    "            label_color = 'black'\n",
    "\n",
    "        # In your loop, for each station:\n",
    "        unique_id = f\"station_{station['station_id']}\"  # Create unique class name\n",
    "        label_css = label_css_template.format(\n",
    "            unique_id=unique_id,\n",
    "            label_color=label_color\n",
    "        )\n",
    "\n",
    "        # Add the CSS for this specific label\n",
    "        network_flux_map.get_root().html.add_child(folium.Element(label_css))\n",
    "\n",
    "        # Create the tooltip with the unique class\n",
    "        folium.Tooltip(\n",
    "            station['station_name'],\n",
    "            permanent=True,\n",
    "            direction='top',\n",
    "            offset=(0, -marker_size+4),\n",
    "            class_name=f'label-{unique_id}',\n",
    "        ).add_to(marker)\n",
    "\n",
    "# Add legend\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "            bottom: 50px; left: 50px; width: 200px;\n",
    "            background-color: white; border: 2px solid grey;\n",
    "            z-index: 9999; font-size: 11px; padding: 10px\">\n",
    "    <b>Oslo bike network analysis</b><br><br>\n",
    "    <b>Station types:</b><br>\n",
    "    <span style=\"color: #d73027;\">●</span> Heavy exporter (>2 bikes/day)<br>\n",
    "    <span style=\"color: #fc8d59;\">●</span> Light exporter<br>\n",
    "    <span style=\"color: #ffffbf;\">●</span> Balanced (±0.5 bikes/day)<br>\n",
    "    <span style=\"color: #91cf60;\">●</span> Light importer<br>\n",
    "    <span style=\"color: #1a9850;\">●</span> Heavy importer (>2 bikes/day)<br>\n",
    "    <br>\n",
    "    <b>Visual elements:</b><br>\n",
    "    • Size = Total daily usage<br>\n",
    "    • Thick border = Top 5 exporter/importer<br>\n",
    "    • Blue lines = Trip frequency<br>\n",
    "    • Labels = Top stations by PageRank<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ Top 5 exporters/importers\n",
    "</div>\n",
    "'''\n",
    "network_flux_map.get_root().html.add_child(folium.Element(legend_html)) \n",
    "\n",
    "# Add title\n",
    "title_html = '''\n",
    "<div style=\"position: fixed; \n",
    "            top: 10px; left: 50%; transform: translateX(-50%);\n",
    "            background-color: white; border: 2px solid grey;\n",
    "            z-index: 9999; font-size: 16px; font-weight: bold;\n",
    "            text-align: center; padding: 8px 15px;\n",
    "            border-radius: 5px;\">\n",
    "    Oslo bike network: Importer vs. exporter stations\n",
    "</div>\n",
    "'''\n",
    "network_flux_map.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "network_flux_map.save('../outputs/network_flux_map.html')\n",
    "network_flux_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c80bde4",
   "metadata": {},
   "source": [
    "The network map above shows two distinct network areas:\n",
    "  \n",
    "**The core network (dense central area)**  \n",
    "- High traffic density with many connections\n",
    "- Net bike **importers** (accumulate bikes throughout the day)\n",
    "- Short frequent trips between nearby stations\n",
    "- High intra-city circulation  \n",
    "  \n",
    "This dense network serves daily urban activites, such as shopping, errands, meetings and so on. Bikes circulate actively within this zone as people move between neighborhoods.  \n",
    "  \n",
    "**The feeder network (peripheral stations)**\n",
    "- Lower traffic density, fewer connections\n",
    "- Net bike **exporters** (lose bikes throughout the day)\n",
    "- More isolated from each other\n",
    "  \n",
    "These stations act as \"park and ride\" points for communters. People living in elevated residential areas use bikes for one-way trips into the city center, then use other transport to return home. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8c514-5025-41b2-98e1-224ec7db76fa",
   "metadata": {},
   "source": [
    "### 3.5 Summary: Network structure insights\n",
    "The network analysis shows that Oslo's bike sharing system can be split into two distinct zones, the core (importer) zone and the feeder (exporter) zone:  \n",
    "  \n",
    "**Core vs. feeder network structure:** The **core network** consists of densely connected central stations such as Aker Brygge, Oslo S and Torggata. These act as bike importers. They consistently receive more bikes than they send out. This is the zone where the majority of the bike rides take place. Surrounding this core is a **feeder network** of peripheral stations at higher elevations that primarily export bikes downhill into the city center.  \n",
    "  \n",
    "The top routes fall into **two main categories**:\n",
    "- **Leisure routes:** These are short rides along the waterfront, like Aker Brygge ↔ Vippetangen. These routes are most frequent, but make up only about 1% of all rides. \n",
    "- **Commuter routes**: High-frequency connections between high-PageRank stations like Torggata ↔ Alexander Kiellands Plass. These are the backbone of the network and serve commuter rides.  \n",
    "  \n",
    "This analysis clearly demonstrates how the network is structured. However, there is one important aspect that I have glossed over, which is temporal patterns. I will address these in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef110bc",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Phase 3: Temporal pattern analysis\n",
    "Having identified Oslo's dual-zone network structure (central importers vs. peripheral feeders), we now examine **when** these patterns emerge throught the day.  \n",
    "  \n",
    "This analysis will show how the gravitational flow we discovered earlier plays out hour by hour. This is critical information to plan when trucks have to go out and restock stations or remove bikes from fully stocked ones so that users can park their bikes.  \n",
    "  \n",
    "**Key questions to answer:**  \n",
    "1. When do the peripheral stations feed the central ones?  \n",
    "2. How do different station types behave throughout the day?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe167758",
   "metadata": {},
   "source": [
    "### 4.1 Data preparation: timezone correction\n",
    "Before analyzing temporal patterns, we need to fix an issue with the time stap of the dataset:  \n",
    "  \n",
    "The original dataset shows a an unusual rush hour pattern with peaks at 4-7 and 13-16, clearly outside of normal commuting hours. In addition, trips are outside of the offical opening hours of the bike sharing system, which is from 5 in the morning until 1 o'clock at night.  \n",
    "  \n",
    "**Problem**: The data appears to be in UTC timezone, while Oslo is on CET/CEST (central european time).  \n",
    "**Solution**: We need to convert the timezone to the appropriate one while automatically handling daylight saving time.  \n",
    "**Validation**: After time zone conversion, the bike usage hours align perfectly with Oslo Bysykkel's official operating hours (05:00 - 01:00), and the rush hour patterns appear at normal commuting times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix time stamp\n",
    "trips['started_at'] = pd.to_datetime(trips['started_at']).dt.tz_localize('UTC').dt.tz_convert('Europe/Oslo')\n",
    "trips['ended_at'] = pd.to_datetime(trips['ended_at']).dt.tz_localize('UTC').dt.tz_convert('Europe/Oslo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fcf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hour to trips table\n",
    "trips['hour'] = trips['started_at'].dt.hour\n",
    "\n",
    "plt.hist(trips['hour'], bins=23, color='skyblue', edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "plt.axvspan(7, 9, alpha=0.3, color='gray', label='Morning rush')\n",
    "plt.axvspan(15, 18, alpha=0.3, color='gray', label='Evening rush')\n",
    "\n",
    "plt.xticks(range(24))\n",
    "plt.xlabel('Hour of day')\n",
    "plt.ylabel('Number of trips')\n",
    "plt.title('System-wide bike usage throughout the day')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea076a8",
   "metadata": {},
   "source": [
    "### 4.2 When do perpheral stations feed the central ones? Extreme station patterns\n",
    "Let's first look at how the daily flux of bikes develops throughout the day. We will start by looking at the most extreme stations, wich are the top most exporting and importing stations.  \n",
    "  \n",
    "To achieve an overview of the daily pattern in the flux of bikes, we need to group the dataset by 'hour of day' and then count the hourly arrivals and departures. This will give us the average flux behaviour over the entire year, smoothing out any seasonal variations such as winter and summmer or weekends and week days, retaining only variations caused by the time of day.  \n",
    "  \n",
    "#### 4.2.1 Top exporters and importers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hourly flux for each station\n",
    "hourly_arrivals = trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Get top n exporters and importers\n",
    "n = 5\n",
    "top_importers = station_flux.nlargest(n, 'net_flux_daily')\n",
    "top_exporters = station_flux.nsmallest(n, 'net_flux_daily')\n",
    "\n",
    "importer_stations = top_importers['station_id'].tolist()\n",
    "exporter_stations = top_exporters['station_id'].tolist()\n",
    "\n",
    "# Plot top exporters and importers\n",
    "plt.figure()\n",
    "# Plot exporters\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    # color=plt.cm.rainbow(0.6 + 0.4 * (i / n))\n",
    "    plt.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "    \n",
    "# Plot importers\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    # color=plt.cm.rainbow(0.6 + 0.4 * (i / n))\n",
    "    plt.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "    \n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "plt.xticks(range(24))\n",
    "plt.xlabel('Hour of day')\n",
    "plt.ylabel('Daily net flux (arrivals - departures)')\n",
    "plt.title('Extreme stations: Top exporters vs. top importers')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/imbalanced_stations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375166be",
   "metadata": {},
   "source": [
    "**Key findings**:  \n",
    "  \n",
    "**Exporter station** behaviour (blue lines - feeder network):  \n",
    "- **Consistent daily export**: All exporter stations remain largly negative throughout the day, indicating that bikes mainly flow one-way.  \n",
    "- **Long morning rush (05-09)**  \n",
    "- **There are some local exceptions:**\n",
    "    - **Lindern (Ullevål Hospital)**: Brief import spikes at 06-07 and two large export spikes; one at 15:00 (probably hospital day shift ending) and another at 22:00 (evening shift ending).  \n",
    "    - **BI Nydalen**: Brief import spike at 07-08, probably students and employees arriving at the BI campus. \n",
    "- **No evening return**: Confirms that people don't bike back uphill, they use other means of transportation.  \n",
    "  \n",
    "**Importer station** behavior (red lines - core network):  \n",
    "- **Strong morning influx (07-09)**: All downtown stations show large positive spikes, with peakes reaching 6+ bikes per hour net inflow.\n",
    "- **Sustained high import levels throughout the day**.\n",
    "- **Variable afternoon patterns (14-17)**:  \n",
    "    - **Oslo S and Aker Brygge:** Import fluxes spike again, probably because they are major transport hubs and important areas for leisure activities.  \n",
    "    - **Other core stations**: Show more variable patterns, with some even breifly exporting bikes.  \n",
    "- **Evening activities:**  \n",
    "    - **Torggata is the top evening importer:** This area is a popular destination for evening entertainment, dining and drinks. People bike there after work for social activities. \n",
    "\n",
    "**Note**: These patterns represent the system behaviour average across the entire year. The true pattern of on any day of the year might be significanlty different, based on seasonal effects (summer/winter),, weather conditions (temperature, rain) and day of week (weekend or weekday). Later sections in this analysis will explore these in more detail. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f61c3",
   "metadata": {},
   "source": [
    "### 4.3 Balanced stations\n",
    "Let's now turn our attention to bike stations at intermediate elevations where the bike flow is more balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1193f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top balanced stations\n",
    "balanced_stations = station_flux[\n",
    "    (station_flux['net_flux'].abs() < 500) & # Small imbalance\n",
    "    (station_flux['total_usage'] > 5000)     # High usage\n",
    "].nlargest(n,'total_usage')\n",
    "\n",
    "# Plot top balanced stations\n",
    "plt.figure()\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    plt.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "    \n",
    "# Add rush hour shading\n",
    "plt.axvspan(6, 9, alpha=0.1, color='gray', label='Morning rush')\n",
    "plt.axvspan(14.5, 17.5, alpha=0.1, color='gray', label='Afternoon rush')\n",
    "    \n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "plt.xticks(range(24))\n",
    "plt.xlabel('Hour of day')\n",
    "plt.ylabel('Daily net flux (arrivals - departures)')\n",
    "plt.title('Balanced stations: Line crosses zero throughout the day')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/balanced_stations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc19f6a",
   "metadata": {},
   "source": [
    "**Key findings:**  \n",
    "**Balanced stations have a clear zero-crossing:**  \n",
    "- Lines cross the `y=0` axis, which indicates a two-way flow.\n",
    "There is no persistent directional bias. Bikes flow both in and out throughout the day.  \n",
    "  \n",
    "**Clear temporal patterns**:\n",
    "- **Morning outflow (06-09):** These stations show negative spikes, suggesting people leave these areas for work.  \n",
    "- **Afternoon influx (15-18):** As opposed to importer and exporter stations, here there is a clear sign that commuters actually return home by bike, which causes the large influx spike in the afternoon.  \n",
    "- **Alexander Kiellands Plass** shows extreme pattern: Dramatic morning exports (-7 bikes/hour) followed by strong afternoon import (6+ bikes/hour). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2c14b7",
   "metadata": {},
   "source": [
    "### 4.4 Weekday vs. weekend patterns\n",
    "Let's investigate how the daily flow pattern differs between weekdays and weekends. The question to answer is whether the system is more popular for weekday commutes or weekend leisure rides. The metrics to look into first are the **daily trip count** and the **daily ride duration** for each day of the week. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde28c2",
   "metadata": {},
   "source": [
    "#### 4.4.1 Trip count and mean duration\n",
    "The following plots show the **average number of rides** and the **average trip duration** by day of the week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "trips['weekday'] = trips['started_at'].dt.day_name()\n",
    "\n",
    "weekly_count_stats = trips.groupby('weekday').size() / 52\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "colors = {\n",
    "    'Monday': 'steelblue',\n",
    "    'Tuesday': 'steelblue', \n",
    "    'Wednesday': 'steelblue', \n",
    "    'Thursday': 'steelblue', \n",
    "    'Friday': 'steelblue', \n",
    "    'Saturday': 'lightsteelblue', \n",
    "    'Sunday': 'lightsteelblue'}\n",
    "\n",
    "bars = plt.bar(day_order, [weekly_count_stats[day] for day in day_order],\n",
    "               color=[colors[day] for day in day_order],\n",
    "            edgecolor='black', linewidth=0.5, alpha=0.8)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    x = bar.get_x()\n",
    "    width = bar.get_width()\n",
    "    plt.text(x+width/2., height+50, f'{height:.0f}', ha='center',\n",
    "             va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Average daily bike usage: weekdays dominate\")\n",
    "plt.xlabel('Day of week')\n",
    "plt.ylabel('Average trips per day')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekly_usage_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92930da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute stats\n",
    "weekday = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "weekend = ['Saturday', 'Sunday']\n",
    "weekday_mean = weekly_count_stats.loc[weekday].mean()\n",
    "weekend_mean = weekly_count_stats.loc[weekend].mean()\n",
    "\n",
    "difference = (weekday_mean - weekend_mean)/weekday_mean * 100\n",
    "print(f\"Rides on the weekend are {difference:.0f}% less frequent than weekday rides.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "weekly_duration_stats = trips.groupby('weekday').mean() / 60\n",
    "\n",
    "bars = plt.bar(day_order, [weekly_duration_stats['duration'][day] for day in day_order],\n",
    "               color=[colors[day] for day in day_order],\n",
    "            edgecolor='black', linewidth=0.5, alpha=0.8)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    x = bar.get_x()\n",
    "    width = bar.get_width()\n",
    "    plt.text(x+width/2., height+0.2, f'{height:.0f}', ha='center',\n",
    "             va='bottom', fontsize=10)\n",
    "    \n",
    "plt.title('Average daily trip duration: weekend trips longer')\n",
    "plt.xlabel('Day of week')\n",
    "plt.ylabel('Average daily trip duration [min]')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekly_usage_duration.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5275c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_mean = weekly_duration_stats.loc[weekday,:]['duration'].mean()\n",
    "weekend_mean = weekly_duration_stats.loc[weekend,:]['duration'].mean()\n",
    "\n",
    "difference = (weekend_mean - weekday_mean)/weekday_mean * 100\n",
    "print(f\"Rides on the weekend are {difference:.0f}% longer than on weekdays.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf04617",
   "metadata": {},
   "source": [
    "**Key findings:**  \n",
    "While intuition might suggest that the bike sharing system is predominantly used for leisure rides, the plots above paint a different picture:\n",
    "- Rides on the weekend are actually 37% less frequent than on weekdays.\n",
    "- However, rides on the weekend are on average 25% longer than on weekdays.  \n",
    "  \n",
    "This shows that Oslo's bike sharing system is an integrated component in the city's transportation infrastructure, frequently used for commuting purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e49577",
   "metadata": {},
   "source": [
    "#### 4.4.2 Flux analysis\n",
    "Now let's examine how the station imbalance patterns we identified earlier differ between weekdays and weekends. Using the same net flux analysis from previous sections, I'll split the data by day of the week to see if commuter and leisure behavior creates different flow patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfceb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_trips = trips[trips['weekday'].isin(['Saturday', 'Sunday'])]\n",
    "weekday_trips = trips[~trips['weekday'].isin(['Saturday', 'Sunday'])]\n",
    "\n",
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# WEEKDAY PLOT (Left)\n",
    "# Calculate hourly flux for weekdays\n",
    "hourly_arrivals = weekday_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekday_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekday subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers on weekday subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of day')\n",
    "ax1.set_ylabel('Daily net flux (arrivals - departures)')\n",
    "ax1.set_title('Weekdays: strong commuter patterns')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([-3, 7])\n",
    "\n",
    "\n",
    "# WEEKEND PLOT (Right)\n",
    "# Calculate hourly flux for weekends\n",
    "hourly_arrivals = weekend_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekend_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekend subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers on weekend subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Weekends: gentler leisure patterns')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Title\n",
    "plt.suptitle('Daily bike flow for extreme importer and exporter stations', fontsize=17)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekday_vs_weekend.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# WEEKDAY PLOT (Left)\n",
    "# Calculate hourly flux for weekdays\n",
    "hourly_arrivals = weekday_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekday_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekday subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Weekdays: strong commuter patterns')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([-8, 6])\n",
    "\n",
    "\n",
    "# WEEKEND PLOT (Right)\n",
    "# Calculate hourly flux for weekends\n",
    "hourly_arrivals = weekend_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekend_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekend subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "\n",
    "\n",
    "ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Weekends: gentler leisure patterns')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Title\n",
    "plt.suptitle('Daily bike flow for balanced stations', fontsize=17)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekday_vs_weekend_balanced.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f42e9",
   "metadata": {},
   "source": [
    "**Key observations:**\n",
    "- The weekday flux patterns look almost identical to the earlier analysis of the full dataset. \n",
    "- The huge morning exports and afternoon imports are primarily weekday phenomena. \n",
    "- Both balanced and extreme stations show only small flux variation throughout the day on weekends.\n",
    "- Weekend usage tends to be a lot more balanced than weekday usage.  \n",
    "  \n",
    "**Note**: A line near zero indicates balanced inflow and outflow of bikes, not necessarily low usage. To understand the actual station activity, we'll reproduce the figures using total usage instead.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0019b",
   "metadata": {},
   "source": [
    "#### 4.4.3 Total usage analysis\n",
    "A net flux near zero provides information on how many bikes a station gains or loses over a certain period of time. However, it doesn't inform us about how many bikes are used in total, as a large number of incoming bikes and outgoing bikes produce the same result as a small number. In this section, we will reproduce the previous plot, but this time we'll look at the total station usage, as opposed to the bike flux. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# WEEKDAY PLOT (Left)\n",
    "# Calculate hourly total usage for weekdays\n",
    "hourly_arrivals = weekday_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekday_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_total_usage = (hourly_arrivals + hourly_departures)/365\n",
    "hourly_total_usage = hourly_total_usage.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekday subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers on weekday subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "# ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Weekdays: strong commuter patterns')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "# ax1.set_ylim([-3, 7])\n",
    "\n",
    "\n",
    "# WEEKEND PLOT (Right)\n",
    "# Calculate hourly total usage for weekends\n",
    "hourly_arrivals = weekend_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekend_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_total_usage = (hourly_arrivals + hourly_departures)/365\n",
    "hourly_total_usage = hourly_total_usage.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekend subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers on weekend subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "# ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Weekends: gentler leisure patterns')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Title\n",
    "plt.suptitle('Daily total activity for extreme stations', fontsize=17)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekday_vs_weekend_total_usage.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f52212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# WEEKDAY PLOT (Left)\n",
    "# Calculate hourly total usage for weekdays\n",
    "hourly_arrivals = weekday_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekday_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_total_usage = (hourly_arrivals + hourly_departures)/365\n",
    "hourly_total_usage = hourly_total_usage.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekday subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Weekdays: strong commuter patterns')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "# ax1.set_ylim([-8, 6])\n",
    "\n",
    "\n",
    "# WEEKEND PLOT (Right)\n",
    "# Calculate hourly total usage for weekends\n",
    "hourly_arrivals = weekend_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekend_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_total_usage = (hourly_arrivals + hourly_departures)/365\n",
    "hourly_total_usage = hourly_total_usage.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekend subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "\n",
    "\n",
    "# ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Weekends: gentler leisure patterns')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Title\n",
    "plt.suptitle('Daily total activity for balanced stations', fontsize=17)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekday_vs_weekend_total_usage_balanced.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d02383a",
   "metadata": {},
   "source": [
    "**Key finding:**  \n",
    "- Central stations handle up to 16 trips per hour during weekday peaks while fewer than 4 per hour on the weekend.  \n",
    "- Stations that appeared inactive in the flux analysis actually maintain steady 2-3 trips per hour throughout weekends.  \n",
    "- The flat weekend flux lines actually represented two-way traffic, not low usage.  \n",
    "- As expected, the rush hour peaks are only a thing on weekdays. \n",
    "- Weekend usage is more gentle with less pronounced peaks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c02758",
   "metadata": {},
   "source": [
    "### 4.5 Summer vs. year-round patterns\n",
    "The previous analyses used all data throughout the year. Knowing Oslo's climate, it seems natural that most of the bike traffic happens during the summer months. In this section we'll compare how much the bike flow patterns vary between the summer months and the remaining months of the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3357cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['month'] = trips['started_at'].dt.month\n",
    "summer_trips = trips[trips['month'].isin([6, 7, 8])]\n",
    "nonsummer_trips = trips[~trips['month'].isin([6, 7, 8])]\n",
    "\n",
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# SUMMER PLOT (Left)\n",
    "# Calculate hourly flux for summer\n",
    "hourly_arrivals = summer_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = summer_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/90\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters in summer subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers in summer subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Summer')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([-6, 12])\n",
    "\n",
    "\n",
    "# REST OF YEAR PLOT (Right)\n",
    "# Calculate hourly flux for rest of year\n",
    "hourly_arrivals = nonsummer_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = nonsummer_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/270\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters rest of year subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers rest of year subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Rest of year')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Title\n",
    "plt.suptitle('Daily bike flow for extreme importer and exporter stations', fontsize=17)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/summer_vs_rest_of_year.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# SUMMER PLOT (Left)\n",
    "# Calculate hourly flux for weekdays\n",
    "hourly_arrivals = summer_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = summer_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/90\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot balanced stations in summer subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Summer')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([-12, 9])\n",
    "\n",
    "\n",
    "# REST OF YEAR PLOT (Right)\n",
    "# Calculate hourly flux for rest of year\n",
    "hourly_arrivals = nonsummer_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = nonsummer_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/270\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot balanced stations for rest of year subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "\n",
    "\n",
    "ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Rest of year')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Title\n",
    "plt.suptitle('Daily bike flow for balanced stations', fontsize=17)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/summer_vs_rest_of_year_balanced.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92601e",
   "metadata": {},
   "source": [
    "**Key findings**:\n",
    "- Summer amplifies the flux patterns but doesn't change the fundamental behavior.\n",
    "- Central stations reach flux peaks of 11+ bikes/hour in summer vs. 5-6 during the rest of the year.\n",
    "- The same morning export and afternoon import patterns persist year-round, just at different intensities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5d41e-2530-42fe-8efb-db1702819eb4",
   "metadata": {},
   "source": [
    "### 4.6 Summary: Temporal insights\n",
    "The temporal analysis showed that bike stations follow distinctive and predictable daily and weekly patterns.  \n",
    "  \n",
    "First of all, **weekdays dominate** the system usage. Trips are 37% more frequent during the week than on weekends, and the daily patterns show very different behavior. On weekdays, stations can be classified into one of three categories:\n",
    "- **Exporter stations**: Consistently lose bikes with no evening return flow\n",
    "- **Importer stations**: Accumulate bikes throughout weekday mornings and evenings\n",
    "- **Balanced stations**: Show two-way commuter flows with morning export peak and afternoon import peak\n",
    "  \n",
    "Secondly, seasonal and weekly variations follow predictable patterns:\n",
    "- Leisure riding on weekends flattens all imbalances and creates gentler flows.\n",
    "- Summer amplifies existing patterns without changing the fundamental behavior.\n",
    "  \n",
    "These patterns demonstrate the daily challenges to redistribute bikes such that they are available for morning commutes and ensure docking capacity to end rides. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13195f19-402c-4ae2-bf5c-903d32961013",
   "metadata": {},
   "source": [
    "## 5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60280c6d",
   "metadata": {},
   "source": [
    "This analysis set out to understand how Oslo's bike sharing system really works. It turned out that the movement of bikes is not completely random, but is in fact guided by very predictable patterns. Three important aspects control the movements of bikes around town.  \n",
    "  \n",
    "The **gravity problem**: The topographical analysis showed that cyclists have a strong preference for downhill over uphill travel. 59.6% of all rides go downhill while only 38.8% go uphill. People tend to ride bikes from higher elevations down to lower elevations in the city center, and then take other means of transportation back home. This leads to a depletion of bikes at elevations over ~35 meters, and stations lower than that consistently accumulate bikes. Without proper countermeasures, uphill stations would soon run out of bikes while downhill stations would run out of docking capacity.  \n",
    "  \n",
    "**Two-zone structure**: The network analysis showed that the network can be divided into two parts. The first is the **core network** in downtown areas where most of the rides take place. This area acts as a bike sink where stations such as Aker Brygge, Oslo S and Torggata persistently import bikes throughout the day. Surrounding this core network is the **feeder network** of peripheral stations, which primarily export bikes downhill each day. The most popular routes fall into two categories: Short waterfront leisure rides and high-frequency commuter rides between major downtown hubs.  \n",
    "  \n",
    "**Weekday travel dominates:** The temporal analysis showed that weekdays dominate the bike-sharing network. Weekday trips are 37% more frequent than weekend trips. Different stations show very different bike fluxes throughout the day. Balanced stations function as large bike exporters in the morning and as large importers in the evening. Downtown stations are mainly importers throughout the entire day, while peripheral stations mainly export. This pattern is much less extreme on weekends and becomes flattened. \n",
    "  \n",
    "These three effects drive the bike flow in Oslo. Understanding these patterns shows that bike rebalancing in Oslo isn't random maintenance, but a daily battle against gravity. Restocking and bike removal needs follow predictable patterns controlled by time and location.  \n",
    "  \n",
    "This was a fun weekend project and shows the power of data science. Analyses like this allow us to extract patterns from seemingly random datasets and provide answers to concrete questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c289e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f10ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results back to DuckDb?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
