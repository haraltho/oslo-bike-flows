{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49ed6fa",
   "metadata": {},
   "source": [
    "# Oslo Bike Share System Analysis\n",
    "\n",
    "Oslo's bike-sharing system, *Bysykkel*, is a popular way to get around the city. Historical ride data is freely available — a paradise for any data scientist. In this project, I explore how topography influences bike movement patterns, identify critical stations in the network, and examine rebalancing needs and temporal usage dynamics.\n",
    "\n",
    "## Project Goal\n",
    "\n",
    "To discover actionable insights about Oslo’s bike-sharing system by analyzing patterns driven by topography, network structure, and temporal dynamics — with the aim of supporting operational improvements and user experience.\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. **How does topography affect the flow of bikes?**\n",
    "2. **Which stations are most important to the network?**\n",
    "3. **What temporal patterns drive rebalancing needs?**\n",
    "4. **How can the system be optimized for better efficiency and reliability?**\n",
    "\n",
    "**Data Source:** [Oslo Bysykkel Historical Data](https://oslobysykkel.no/apne-data/historisk) (using all data from 2024)\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "1. **Data Exploration**\n",
    "2. **Cleaning in SQL**\n",
    "3. **Topographical Flow Analysis**\n",
    "4. **Network Structure Analysis**\n",
    "5. **Temporal Flow Analysis**\n",
    "6. **Rebalancing Insights & Optimization**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import glob\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import math\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-whitegrid')  # or 'default', 'ggplot', etc.\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'axes.labelsize': 11,\n",
    "    'grid.alpha': 0.3\n",
    "})\n",
    "\n",
    "# Folium parameters\n",
    "oslo_coordinates = [59.92381785337289, 10.746284281064217]\n",
    "zoom = 14.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c610395",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "In this phase, we'll explore the dataset in order to find data quality issues. The findings will be used to determine what cleaning steps are needed.\n",
    " \n",
    "### 1.1 Loading the data\n",
    "This step reads all monthly CSV files from the `../data/` folder and loads them into a DuckDB database file (`db/bysykkel_2024.duckdb`). If the database doesn't exist, it will be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSVs into DuckDB table 'trips_raw'\n",
    "con = duckdb.connect(\"../db/bysykkel_2024.duckdb\")\n",
    "\n",
    "# csv_files = glob.glob(\"../data/??.csv\")\n",
    "# for i, file in enumerate(csv_files):\n",
    "#     if i == 0:\n",
    "#         con.execute(f\"CREATE OR REPLACE TABLE trips_raw AS SELECT * FROM read_csv_auto('{file}')\")\n",
    "#     else:\n",
    "#         con.execute(f\"INSERT INTO trips_raw SELECT * FROM read_csv_auto('{file}')\")\n",
    "\n",
    "# con.execute(\"CHECKPOINT\")\n",
    "# print(\"Loaded trips_raw data into DuckDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896a7df",
   "metadata": {},
   "source": [
    "### 1.2 Exploring Dataset and Columns\n",
    "In this step we'll explore all the columns to get familiar with the dataset and detect data quality issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d50a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = con.execute('SELECT * FROM trips_raw').df()\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbb9732",
   "metadata": {},
   "source": [
    "The dataset contains 13 columns, where each column represents one ride. Only the `start_station_description`and the `end_station_description` contain null values. These columns contain no value to the project and will be discarded.  \n",
    "  \n",
    "❗ Drop start_station_description and end_station_description columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6b0447",
   "metadata": {},
   "source": [
    "#### 1.2.1 started_at & ended_at\n",
    "These columns state the times at which a ride was started and ended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d67fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Check if ended_at is always after started_at\n",
    "(trips['ended_at'] >= trips['started_at']).all()\n",
    "print(f\"Are all return times after the trip was started? {(trips['ended_at'] >= trips['started_at']).all()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbda590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot usage frequency\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Group by day\n",
    "daily = trips.groupby(trips['started_at'].dt.date).size()\n",
    "\n",
    "# Convert index to datetime (from date)\n",
    "daily.index = pd.to_datetime(daily.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(daily.index, daily.values, color='royalblue')\n",
    "\n",
    "# Format x-axis with months\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "plt.title(\"Daily Ride Count (Binned by Day)\")\n",
    "plt.xlabel(\"Month [2024]\")\n",
    "plt.ylabel(\"Number of Rides\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/daily_ride_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802298e0",
   "metadata": {},
   "source": [
    "✅ No problems detected in this column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10326732",
   "metadata": {},
   "source": [
    "#### 1.2.2 Duration\n",
    "The `duration` column states the duration of the ride in seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot duration distribution, log scale helps\n",
    "plt.figure()\n",
    "sns.histplot(data=trips, x='duration', bins=100, log_scale=True)\n",
    "plt.title(\"Ride Duration\")\n",
    "plt.xlabel(\"Ride Duration [sec]\")\n",
    "plt.axvline(7200, c='grey', linewidth=0.5, linestyle='--', label=\"2h\")\n",
    "plt.legend(frameon=False)\n",
    "plt.ylabel(\"Number of Rides\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "There are {(trips[trips['duration']>7200]).size} rides that exceed 2 hours. It is likely that these are not actual rides but bikes that were unsuccessfully returned. We will remove these from the dataset.  \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba57aaa",
   "metadata": {},
   "source": [
    "✅ No missing values.  \n",
    "❗ Remove rides longer than 2 hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6d685",
   "metadata": {},
   "source": [
    "#### 1.2.3 start_station_id & end_station_id\n",
    "These columns state a unique id for each station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35319b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of start stations: {len(set(trips['start_station_id']))}\")\n",
    "print(f\"Number of start stations: {len(set(trips['end_station_id']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ids = set(trips['start_station_id'].unique())\n",
    "end_ids = set(trips['end_station_id'].unique())\n",
    "\n",
    "only_start = start_ids - end_ids\n",
    "only_end = end_ids - start_ids\n",
    "\n",
    "print(f\"Start-only stations: {len(only_start)}\")\n",
    "print(f\"End-only stations: {len(only_end)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7867546",
   "metadata": {},
   "source": [
    "Check how many trips are **loops**, so trips where the start and end stations are identical. These might distort the picture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5978b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(trips[trips['start_station_id']==trips['end_station_id']])} trips with identical start and end point. These will be discarded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970454f6",
   "metadata": {},
   "source": [
    "✅ No missing values.  \n",
    "❗ Remove loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40c4cc",
   "metadata": {},
   "source": [
    "#### 1.2.3 start_station_name & end_station_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bca24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of start stations: {len(set(trips['start_station_name']))}\")\n",
    "print(f\"Number of start stations: {len(set(trips['end_station_name']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e23a4c",
   "metadata": {},
   "source": [
    "There are two more unique station names than station id's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_names = set(trips['start_station_name'].unique())\n",
    "end_names = set(trips['end_station_name'].unique())\n",
    "\n",
    "only_start_names = start_names - end_names\n",
    "only_end_names = end_names - start_names\n",
    "\n",
    "print(f\"Start-only station names: {len(only_start_names)}\")\n",
    "print(f\"End-only station names: {len(only_end_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_name_map = (\n",
    "    trips[['start_station_id', 'start_station_name']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('start_station_id')['start_station_name']\n",
    "    .nunique()\n",
    ")\n",
    "\n",
    "# IDs with >1 unique name\n",
    "inconsistent_ids = start_name_map[start_name_map > 1]\n",
    "print(f\"Start station IDs with multiple names: {len(inconsistent_ids)}\")\n",
    "print(inconsistent_ids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59429188",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_name_map = (\n",
    "    trips[['end_station_id', 'end_station_name']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('end_station_id')['end_station_name']\n",
    "    .nunique()\n",
    ")\n",
    "\n",
    "# IDs with >1 unique name\n",
    "inconsistent_ids = end_name_map[end_name_map > 1]\n",
    "print(f\"End station IDs with multiple names: {len(inconsistent_ids)}\")\n",
    "print(inconsistent_ids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trips[trips['start_station_id']==608]\n",
    "df['start_station_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a58171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trips[trips['start_station_id']==1101]\n",
    "df['start_station_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c700f",
   "metadata": {},
   "source": [
    "❗ station_id 608 and 1101 don't have unique names. There is a small subset (~1%) of alternative names. When creating a station table it is important to use the station_id as the unique identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17734cc",
   "metadata": {},
   "source": [
    "#### 1.2.4 start_station_latitude, end_station_latitude, start_station_longitude, end_station_longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479458d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "trips['start_station_latitude'].hist(ax=axs[0, 0], bins=50, color='skyblue')\n",
    "axs[0, 0].set_title('Start Station Latitude')\n",
    "\n",
    "trips['end_station_latitude'].hist(ax=axs[0, 1], bins=50, color='lightgreen')\n",
    "axs[0, 1].set_title('End Station Latitude')\n",
    "\n",
    "trips['start_station_longitude'].hist(ax=axs[1, 0], bins=50, color='skyblue')\n",
    "axs[1, 0].set_title('Start Station Longitude')\n",
    "\n",
    "trips['end_station_longitude'].hist(ax=axs[1, 1], bins=50, color='lightgreen')\n",
    "axs[1, 1].set_title('End Station Longitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89800c93",
   "metadata": {},
   "source": [
    "### Column Audit Summary\n",
    "\n",
    "| Column                      | Notes                                                                 |\n",
    "|-----------------------------|-----------------------------------------------------------------------|\n",
    "| `started_at`, `ended_at`    | ✅ Valid timestamps, no missing values. |\n",
    "| `duration`                  | ⚠️ No missing values, but contains outliers > 2 hours → to be removed in SQL. |\n",
    "| `start_station_id`          | ✅ Valid IDs. However, 30,188 trips are loops (start = end) → to be removed. |\n",
    "| `end_station_id`            | ✅ Valid IDs. Same note as above.                                    |\n",
    "| `start_station_name`        | ⚠️ Mostly consistent. Two IDs (608 and 1101) map to multiple names. Will use the most common. |\n",
    "| `end_station_name`          | ⚠️ Same as above. No major action needed if we trust IDs.            |\n",
    "| `start_station_description` | ❌ Incomplete. Will be dropped in cleaning step.                 |\n",
    "| `end_station_description`   | ❌ Same as above.                                                    |\n",
    "| `start_station_latitude`    | ✅ All values present. Range appears valid.                          |\n",
    "| `end_station_latitude`      | ✅ Same as above.                                                    |\n",
    "| `start_station_longitude`   | ✅ All values present. Range appears valid.                          |\n",
    "| `end_station_longitude`     | ✅ Same as above.                                                    |\n",
    "\n",
    "\n",
    "### Cleaning Actions to Apply in SQL\n",
    "\n",
    "- Remove trips longer than 2 hours  \n",
    "- Remove loops (start and end station ID are the same)  \n",
    "- Drop `start_station_description` and `end_station_description`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fdb56",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Cleaning in SQL\n",
    "In this step we'll clean the dataset and address the problems identified in our exploration phase.\n",
    "\n",
    "The goal is to create two tables:\n",
    "1. `trips_clean`: A filtered dataset without outliers and unnecessary columns, ready for analysis in pandas\n",
    "2. `stations`: A normalized table listing all stations in the system, containing consistent names, station IDs, and geographic coordinates\n",
    "\n",
    "### 2.1 trips_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70958a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rides longer than 2 hours (= 7200 sec)\n",
    "# Remove loops\n",
    "# Drop station descriptions\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE trips_clean AS\n",
    "SELECT \n",
    "    * EXCLUDE (start_station_description, end_station_description)\n",
    "FROM trips_raw\n",
    "WHERE\n",
    "    duration < 7200 AND\n",
    "    start_station_id != end_station_id\n",
    "\"\"\")\n",
    "con.execute(\"CHECKPOINT\")\n",
    "print(\"Cleaned trips saved to DuckDB as 'trips_clean'\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b8ddd",
   "metadata": {},
   "source": [
    "### 2.2 Extract Unique Stations  \n",
    "Build a `stations` table by combining all distinct start and end stations from the `trips_clean` table. This gives the full list of physical bike stations to enrich with elevation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc295e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE stations AS\n",
    "SELECT DISTINCT\n",
    "    station_id,\n",
    "    station_name,\n",
    "    ROUND(lat, 5) AS lat,\n",
    "    ROUND(lon, 5) AS lon\n",
    "FROM (\n",
    "    SELECT\n",
    "        start_station_id AS station_id,\n",
    "        start_station_name AS station_name,\n",
    "        start_station_latitude AS lat,\n",
    "        start_station_longitude AS lon\n",
    "    FROM trips_clean\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT\n",
    "        end_station_id AS station_id,\n",
    "        end_station_name AS station_name,\n",
    "        end_station_latitude AS lat,\n",
    "        end_station_longitude AS lon\n",
    "    FROM trips_clean\n",
    ")\n",
    "ORDER BY station_id\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"CHECKPOINT\")\n",
    "print(\"Extracted and saved 'stations' table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99263f9f",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Topographical Analysis\n",
    "In this phase of the project, we'll investigate whether Oslo's topography influences bike usage patterns. Oslo has a natural gradient from sea level upwards, which suggests that cyclists might prefer downhill over uphill routes.  \n",
    "\n",
    "**Questions we'll answer:**\n",
    "1. Do cyclists prefer downhill routes? If so, by what margin?\n",
    "2. How does elevation affect station imbalance?\n",
    "3. Which specific stations require the most urgent daily rebalancing?\n",
    "\n",
    "### 3.1 Enhancing Data with Elevation Information\n",
    "Before analyzing the effect of the terrain, we'll need to add elevation information based on the geographic location of each bike station in the system. We do this using a free api service \"open-meteo.com\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stations table and add elevation data\n",
    "csv_path = \"../db/stations_with_elevation.csv\"\n",
    "\n",
    "def get_elevation(row):\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "    \n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/elevation?latitude={lat}&longitude={lon}\")\n",
    "    data = response.json()\n",
    "    return data['elevation'][0]\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    print(\"Found existing data. Loading from csv.\")\n",
    "    stations = pd.read_csv(csv_path)\n",
    "else:\n",
    "    print(\"No csv found. Fetching elevation data from API.\")\n",
    "    stations = con.execute(\"SELECT * FROM stations\").df()\n",
    "    stations = stations.drop_duplicates(subset='station_id')\n",
    "    stations['elevation'] = stations.apply(get_elevation, axis=1)\n",
    "    stations.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"Elevation received for all stations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save elevation data to database\n",
    "con.register(\"stations_df\", stations)\n",
    "con.execute(\"CREATE OR REPLACE TABLE stations AS SELECT * FROM stations_df\")\n",
    "con.unregister(\"stations_df\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich trips with elevation data (overwriting original)\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE trips_clean AS\n",
    "SELECT\n",
    "    t.*,   \n",
    "    s_start.elevation AS start_elevation,\n",
    "    s_end.elevation AS end_elevation,\n",
    "    s_end.elevation - s_start.elevation AS elevation_diff\n",
    "FROM trips_clean t\n",
    "JOIN stations s_start ON t.start_station_id = s_start.station_id\n",
    "JOIN stations s_end ON t.end_station_id = s_end.station_id\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"CHECKPOINT\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78330ed",
   "metadata": {},
   "source": [
    "### 3.2 Loading Analysis-Ready Data into pandas\n",
    "Now that we have clean data with elevation information, we'll load it into pandas for the remainder of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enriched data into pandas for analysis\n",
    "con = duckdb.connect(\"../db/bysykkel_2024.duckdb\")\n",
    "trips = con.execute(\"SELECT * FROM trips_clean\").df()\n",
    "stations = con.execute(\"SELECT * FROM stations\").df()\n",
    "con.close()\n",
    "\n",
    "print(f\"Loaded {len(trips):,} clean trips and {len(stations)} stations\")\n",
    "print(f\"Data spans from {trips['started_at'].min()} to {trips['started_at'].max()}\")\n",
    "\n",
    "# Quick check of our elevation data\n",
    "print(f\"\\nElevation range: {stations['elevation'].min():.1f}m to {stations['elevation'].max():.1f}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a734ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_groups = {\n",
    "    'Tjuvholmen': [534, 479],\n",
    "    'Aker Brygge': [1755, 2358, 558, 2357],\n",
    "    'Vippetangen': [452, 441],\n",
    "    'Oslo S': [443, 392, 599],\n",
    "    'Jernbanetorget': [478, 2328], \n",
    "    'Torggata': [437, 489],\n",
    "    'Alexander Kiellands Plass': [421, 444, 617],\n",
    "    'Arkaden': [545, 577],\n",
    "    'Brugata / Vaterlandsparken': [491, 495],\n",
    "    'Schous Plass': [401, 423, 463],\n",
    "\n",
    "}\n",
    "\n",
    "# Create mapping of old ID to new ID\n",
    "id_mapping = {}\n",
    "for group_name, station_ids in station_groups.items():\n",
    "    new_id = station_ids[0] # Use first id for all stations in the group\n",
    "    for id in station_ids:\n",
    "        id_mapping[id] = new_id\n",
    "\n",
    "\n",
    "# Create grouped dataframe\n",
    "stations_grouped = []\n",
    "\n",
    "for group_name, station_ids in station_groups.items():\n",
    "    station_cluster = stations[stations['station_id'].isin(station_ids)]\n",
    "    stations_grouped.append({\n",
    "        'station_id': station_ids[0],\n",
    "        'station_name': group_name,\n",
    "        'lat': station_cluster['lat'].mean(),\n",
    "        'lon': station_cluster['lon'].mean(),\n",
    "        'elevation': station_cluster['elevation'].mean()\n",
    "        \n",
    "    })\n",
    "\n",
    "\n",
    "# all_grouped_ids = []\n",
    "# for _, ids in station_groups.items():\n",
    "#     for id in ids:\n",
    "#         all_grouped_ids.append(id)\n",
    "all_grouped_ids = [id for ids in station_groups.values() for id in ids]\n",
    "ungrouped_stations = stations[~stations['station_id'].isin(all_grouped_ids)]\n",
    "\n",
    "for _, station in ungrouped_stations.iterrows():\n",
    "    stations_grouped.append({\n",
    "        'station_id': station['station_id'],\n",
    "        'station_name': station['station_name'],\n",
    "        'lat': station['lat'],\n",
    "        'lon': station['lon'],\n",
    "        'elevation': station['elevation']\n",
    "    })\n",
    "stations = pd.DataFrame(stations_grouped)\n",
    "\n",
    "# Create lookup tables\n",
    "name_lookup = stations.set_index('station_id')['station_name'].to_dict()\n",
    "lat_lookup = stations.set_index('station_id')['lat'].to_dict()\n",
    "lon_lookup = stations.set_index('station_id')['lon'].to_dict()\n",
    "\n",
    "\n",
    "\n",
    "trips['start_station_id'] = trips['start_station_id'].map(lambda x: id_mapping.get(x, x))\n",
    "trips['end_station_id'] = trips['end_station_id'].map(lambda x: id_mapping.get(x, x))\n",
    "\n",
    "trips['start_station_name'] = trips['start_station_id'].map(name_lookup)\n",
    "trips['end_station_name'] = trips['end_station_id'].map(name_lookup)\n",
    "trips['start_station_latitude'] = trips['start_station_id'].map(lat_lookup)\n",
    "trips['start_station_longitude'] = trips['start_station_id'].map(lon_lookup)\n",
    "trips['end_station_latitude'] = trips['end_station_id'].map(lat_lookup)\n",
    "trips['end_station_longitude'] = trips['end_station_id'].map(lon_lookup)\n",
    "\n",
    "# Remove loops\n",
    "trips = trips[trips['start_station_id']!=trips['end_station_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32671b",
   "metadata": {},
   "source": [
    "### 3.3 Calculating Trip Distance and Gradient\n",
    "To understand cyclist preferences, we need to calculate two key metrics for each trip:  \n",
    "  \n",
    "- **Distance**: The physical distance between start and end stations using the haversine formula\n",
    "- **Gradient**: The slope percentage (elevation change divided by distance)  \n",
    "  \n",
    "Using these metrics, we can categorize each trip as uphill, downhill, or flat. This helps us to analyze route preferences and quantify any bias toward downhill travel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute travel distance and gradient\n",
    "\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "def compute_distance(row):\n",
    "    start = (row['start_station_latitude'], row['start_station_longitude'])\n",
    "    end = (row['end_station_latitude'], row['end_station_longitude'])\n",
    "    return haversine(start, end, unit=Unit.METERS)\n",
    "\n",
    "trips[\"distance\"] = trips.apply(compute_distance, axis=1)\n",
    "\n",
    "def compute_gradient(row):\n",
    "    if row['distance'] == 0:\n",
    "        return np.nan\n",
    "    return row['elevation_diff'] / row['distance'] * 100\n",
    "\n",
    "trips[\"gradient\"] = trips.apply(compute_gradient, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b69edc",
   "metadata": {},
   "source": [
    "### 3.4 Do Cyclists Prefer Downhill Routes?\n",
    "Now we're ready to analyze whether there's a preference for downhill vs. uphill travel.\n",
    "\n",
    "#### 3.4.1 Gradient Distribution Analysis\n",
    "To understand the overall terrain preferences, we'll first examine the distribution of trip gradients across all rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "n, bins, patches = plt.hist(trips[\"gradient\"], \n",
    "                            bins=200, \n",
    "                            edgecolor=\"black\", alpha=0.7, linewidth=0.2)\n",
    "\n",
    "for i, patch in enumerate(patches):\n",
    "    if bins[i] < 0:\n",
    "        patch.set_facecolor(\"green\")\n",
    "    elif bins[i] > 0:\n",
    "        patch.set_facecolor(\"brown\")\n",
    "    else:\n",
    "        patch.set_facecolor(\"grey\")\n",
    "\n",
    "plt.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.7)\n",
    "plt.xlim([-10, 10])\n",
    "plt.title(\"Gradient Distribution\")\n",
    "plt.xlabel(\"Gradient [%]\")\n",
    "plt.ylabel(\"Frequency of Rides\")\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"green\", label=\"downhill\"),\n",
    "    Patch(facecolor=\"grey\", label=\"flat\"),\n",
    "    Patch(facecolor=\"brown\", label=\"uphill\")\n",
    "]\n",
    "plt.legend(handles=legend_elements)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_gradient = trips[\"gradient\"].mean()\n",
    "n_uphill = len(trips[trips['gradient']>0])\n",
    "n_downhill = len(trips[trips['gradient']<0])\n",
    "n_flat = len(trips[trips['gradient']==0])\n",
    "n_total = len(trips)\n",
    "\n",
    "percent_uphill = n_uphill / n_total * 100\n",
    "percent_downhill = n_downhill / n_total * 100\n",
    "percent_flat = n_flat / n_total * 100\n",
    "net_bias = (n_downhill - n_uphill) / n_total * 100\n",
    "relative_increase = (n_downhill - n_uphill) / n_uphill * 100\n",
    "\n",
    "summary = f\"\"\"\n",
    "gradient median = {median_gradient:.2f}%\n",
    "downhill trips: {percent_downhill:.1f}%\n",
    "uphill trips: {percent_uphill:.1f}%\n",
    "flat trips: {percent_flat:.1f}%\n",
    "net bias towards downhill: {net_bias:.1f}%\n",
    "relative increase: {relative_increase:.1f}%\n",
    "\"\"\"\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12861017",
   "metadata": {},
   "source": [
    "Looking at the histogram, we can observe several key paterns in Oslo's bike sharing usage:  \n",
    "  \n",
    "**Visual Observations:**\n",
    "- Downhill rides (negative gradients) are clearly more common than uphill rides.\n",
    "- There's a pronounced peak at gradient 0%, likely representing popular rides along the flat waterfront paths. \n",
    "- The distribution shows a clear skew towards negative gradients, indicating a preference for downhill travel.  \n",
    "  \n",
    "**Quantitative Analysis:**  \n",
    "Our analysis of all trips reveals the following results:  \n",
    "  \n",
    "- **Downhill trips**: 59.5% of all rides (gradient < 0%)\n",
    "- **Uphill trips**: 38.8% of all rides (gradient > 0%) \n",
    "- **Flat trips**: 1.7% of all rides (gradient = 0%)\n",
    "- **Mean gradient**: -0.44% (indicating an overall downhill bias)  \n",
    "  \n",
    "The data shows that **downhill trips are 53% more common than uphill trips** (59.5% vs 38.8%). This represents a strong preference for downhill routes with important implications for bike rebalancing operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b68a97",
   "metadata": {},
   "source": [
    "#### 3.4.2 Distance and Duration Analysis\n",
    "Counting trips alone might be misleading. We'll also examine how much total distance and time cyclists spend going uphill vs. downhill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5cf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for the slope type\n",
    "def categorize_slope(slope):\n",
    "    if slope < 0:\n",
    "        return \"downhill\"\n",
    "    elif slope > 0:\n",
    "        return \"uphill\"\n",
    "    else:\n",
    "        return \"flat\"\n",
    "    \n",
    "trips['slope_type'] = trips['gradient'].apply(categorize_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(6,10))\n",
    "\n",
    "# Duration histogram\n",
    "sns.histplot(data=trips, x='duration', hue='slope_type', \n",
    "             hue_order=['flat', 'uphill', 'downhill'], \n",
    "             bins=50, kde=True, log_scale=True, ax=ax1, legend=True,\n",
    "             palette=['lightblue', 'salmon', 'green'])\n",
    "ax1.set_title(\"Trip Duration by Gradient Direction\")\n",
    "ax1.set_xlabel(\"Duration [s]\")\n",
    "ax1.set_ylabel(\"Frequency of Rides\")\n",
    "ax1.legend(title=\"\", labels=[\"flat\", \"uphill\", \"downhill\"])\n",
    "\n",
    "\n",
    "# Distance histogram  \n",
    "sns.histplot(data=trips, x='distance', hue='slope_type',\n",
    "             hue_order=['flat', 'uphill', 'downhill'], \n",
    "             bins=80, kde=True, log_scale=True, ax=ax2, legend=True,\n",
    "             palette=['lightblue', 'salmon', 'green'])\n",
    "ax2.set_title(\"Trip Distance by Gradient Direction\") \n",
    "ax2.set_xlabel(\"Distance [m]\")\n",
    "ax2.set_ylabel(\"Frequency of Rides\")\n",
    "ax2.legend(title=\"\", labels=[\"flat\", \"uphill\", \"downhill\"])\n",
    "plt.xlim([50, 5000])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "usage_summary = trips.groupby('slope_type').agg({\n",
    "    'duration': ['sum', 'mean', 'count'],\n",
    "    'distance': ['sum', 'mean']}).round(1)\n",
    "usage_summary.columns = ['Total Duration [s]', 'Average Duration [s]', 'Number of Rides', 'Total Distance [m]', 'Average Distance [m]']\n",
    "print(usage_summary.to_string())\n",
    "\n",
    "# Calculate comparisons (downhill vs. uphill)\n",
    "duration_up = usage_summary.loc['uphill', 'Total Duration [s]']\n",
    "duration_down = usage_summary.loc['downhill', 'Total Duration [s]']\n",
    "distance_up = usage_summary.loc['uphill', 'Total Distance [m]']\n",
    "distance_down = usage_summary.loc['downhill', 'Total Distance [m]']\n",
    "\n",
    "# Calculate percentage differences\n",
    "duration_diff_pct = (duration_down - duration_up) / duration_up * 100\n",
    "distance_diff_pct = (distance_down - distance_up) / distance_up * 100\n",
    "\n",
    "# Per-trip comparison\n",
    "avg_duration_up = usage_summary.loc['uphill', 'Average Duration [s]']\n",
    "avg_duration_down = usage_summary.loc['downhill', 'Average Duration [s]']\n",
    "avg_distance_up = usage_summary.loc['uphill', 'Average Distance [m]']\n",
    "avg_distance_down = usage_summary.loc['downhill', 'Average Distance [m]']\n",
    "\n",
    "time_per_trip_diff = (avg_duration_down - avg_duration_up) / avg_duration_down * 100\n",
    "distance_per_trip_diff = (avg_distance_down - avg_distance_up) / avg_distance_up * 100\n",
    "\n",
    "print(\"\\nKey Comparisons\")\n",
    "print(f\"\"\"\n",
    "      - Downhill trips account for {duration_diff_pct:.1f}% more total ride time.\n",
    "      - Downhill trips cover {distance_diff_pct:.1f}% more total distance.\n",
    "      - Uphill trips take on average {abs(time_per_trip_diff):.1f}% longer per trip.\n",
    "      - Downhill trips cover {distance_per_trip_diff:.1f}% more distance per trip.\n",
    "      \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3e999",
   "metadata": {},
   "source": [
    "#### 3.4.4 Summary: Evidence of Downhill Preference\n",
    "Our analysis provides strong evidence that cyclists prefer downhill routes accross multiple metrics:\n",
    "\n",
    "**Trip Districution:**\n",
    "- 59.5% of trips go downhill vs. 38.8% go uphill (53% more common)\n",
    "- Mean gradient of -0.44 indicates overall bias towards downhill travel\n",
    "\n",
    "**Total System Usage:**\n",
    "- Downhill trips account for 37.6% more total ride time\n",
    "- Downhill trips cover 68.2% more total distance.\n",
    "\n",
    "**Individual Trip Properties:**\n",
    "- Uphill trips take on average 11.5% longer.\n",
    "- Downhill trips cover on average 9.6% more distance.\n",
    "\n",
    "**Answer to Question 1:** Yes, cyclists show a strong preference towards downhill routes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d988fcad",
   "metadata": {},
   "source": [
    "### 3.5 How does elevation affect station imbalance?\n",
    "\n",
    "Having established that customers have a strong preference for downhill trips, we'll now investigate how that affects the net flow of bikes.  \n",
    "\n",
    "#### 3.5.1 Compute net flux per station\n",
    "We will start out by computing the **net flux** per station.  \n",
    "net flux = arriving bikes - departing bikes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the net flux per station\n",
    "flux_out = trips.groupby('start_station_id').size().rename('departures')\n",
    "flux_in = trips.groupby('end_station_id').size().rename('arrivals')\n",
    "\n",
    "station_flux = flux_out.to_frame().join(flux_in.to_frame(), how='outer').fillna(0)\n",
    "station_flux['net_flux'] = station_flux['arrivals'] - station_flux['departures']\n",
    "station_flux['total_usage'] = station_flux['arrivals'] + station_flux['departures']\n",
    "station_flux['net_flux_daily'] = station_flux['net_flux'] / 365\n",
    "station_flux['total_usage_daily'] = station_flux['total_usage'] / 365\n",
    "station_flux['departure_share'] = station_flux['departures'] / station_flux['total_usage']\n",
    "\n",
    "station_flux = stations.join(station_flux, how=\"outer\", on=\"station_id\").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96d58b",
   "metadata": {},
   "source": [
    "#### 3.5.2 Elevation's Impact on Station Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = plt.scatter(station_flux['elevation'], station_flux['net_flux_daily'],\n",
    "                      c=station_flux['total_usage_daily'],\n",
    "                      s=60, alpha=0.7, cmap='RdYlBu_r',\n",
    "                      edgecolors='black', linewidths=0.5)\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Total Station Usage', rotation=270, labelpad=15)\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=2, alpha=0.8)\n",
    "plt.axvline(35, color='orange', linestyle=':', linewidth=2, alpha=0.8, label='Elevation threshold (~35m)')\n",
    "\n",
    "plt.xlabel('Elevation [m]')\n",
    "plt.ylabel('Net Flux per Day (Arrivals - Departures)')\n",
    "plt.title('Station Imbalance vs. Elevation')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e34214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The correlation between elevation and net flux is {station_flux['elevation'].corr(station_flux['net_flux']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f570f08",
   "metadata": {},
   "source": [
    "This figure clearly demonstrates how elevation causes station imbalances in Oslo's bike sharing system.  \n",
    "\n",
    "**Key Observations:**\n",
    "- **Above ~35m elevation**: Stations predominantly export bikes (negative net flux), losing around 5 to 10 bikes per day.\n",
    "- **Below ~35m elevation**: Stations predominantly import bikes (positive net flux), gaining up to 20 bikes per day. \n",
    "- **Correlation**: The relationship shows a correlation of -0.61, indicating a strong relationship between elevation and station balance.\n",
    "\n",
    "**Operational Interpretation:**  \n",
    "Bikes naturally \"flow\" downhill through the system and preferentially accumulate near sea level. This creates a systematic daily imbalance, where:\n",
    "- Higer elevation stations consistently need bike restocking.\n",
    "- Lower elevation stations consistenly need bikes removed to create docking space.\n",
    "- The ~35m elevation mark represents a \"watershed\" for bike flow in the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce37387",
   "metadata": {},
   "source": [
    "#### 3.5.3 Geographic Distribution of Imbalances\n",
    "Having established that there's a strong relation between elevation and station imbalance, let's now visualize these imbalances on a map.  \n",
    "  \n",
    "  The interactive map below shows all bike stations with:  \n",
    "  - **Marker size**: Proportional to total daily usage (larger circles = busier station)\n",
    "  - **Marker color**: Indicates imbalance of the station and magnitude\n",
    "    - **Red stations**: Net exporters (lose bikes daily, need restocking)\n",
    "    - **Green stations**: Net importers (gain bkes daily, need bike removal)\n",
    "    - **Color intensity**: Darker colors indicate larger daily imbalances  \n",
    "\n",
    "This visualization shows the geographic pattern of Oslo's bike flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d139e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 exporters and importers\n",
    "top_exporters = station_flux.nsmallest(10, 'net_flux_daily')\n",
    "top_importers = station_flux.nlargest(10, 'net_flux_daily')\n",
    "critical_ids = set(top_exporters['station_id'].tolist() + top_importers['station_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10291c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive Folium map of Oslo to spatially demonstrate the behaviour where bikes are flowing\n",
    "\n",
    "def get_color(flux_value):\n",
    "    if flux_value > 2.7:\n",
    "        return '#1a9850'     # Dark green - Heavy importer\n",
    "    elif flux_value > 0.5:\n",
    "        return 'yellowgreen' # Light green - Light importer  \n",
    "    elif flux_value >= -0.5:\n",
    "        return 'gray'        # Gray - Balanced (±0.5 bikes/day)\n",
    "    elif flux_value > -2.7:\n",
    "        return '#fc8d59'     # Orange - Light exporter\n",
    "    else:\n",
    "        return '#d73027'     # Red - Heavy exporter\n",
    "    \n",
    "def get_radius(total_usage):\n",
    "    # Normalize usage\n",
    "    return np.interp(total_usage,\n",
    "                     (station_flux['total_usage_daily'].min(), station_flux['total_usage_daily'].max()),\n",
    "                     (2, 17))\n",
    "\n",
    "flux_map = folium.Map(location=oslo_coordinates, zoom_start=zoom, tiles=\"CartoDB positron\")\n",
    "\n",
    "# First, add all non-critical stations\n",
    "for index, row in station_flux.iterrows():\n",
    "    if row['station_id'] not in critical_ids:  # Only non-critical stations\n",
    "        popup_content = f\"\"\"\n",
    "        Station: {row['station_name']} <br>\n",
    "        ID: {row['station_id']} <br>\n",
    "        Elevation: {row['elevation']:.0f}m <br>\n",
    "        Departures: {row['departures']/365:.0f}/day <br>\n",
    "        Arrivals: {row['arrivals']/365:.0f}/day <br>\n",
    "        Total Usage: {row['total_usage_daily']:.0f}/day <br>\n",
    "        Net Flux: {row['arrivals']/365 - row['departures']/365:+.1f}/day\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add marker\n",
    "        folium.CircleMarker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            radius=get_radius(row['total_usage_daily']),\n",
    "            color=get_color(row['net_flux_daily']),\n",
    "            fill=True,\n",
    "            fill_color=get_color(row['net_flux_daily']),\n",
    "            fill_opacity=0.8,\n",
    "            weight=1,\n",
    "            popup=folium.Popup(popup_content, max_width=300)\n",
    "        ).add_to(flux_map)\n",
    "\n",
    "# Then add critical stations on top\n",
    "for index, row in station_flux.iterrows():\n",
    "    if row['station_id'] in critical_ids:  # Only critical stations\n",
    "        popup_content = f\"\"\"\n",
    "        <b>⚠️ CRITICAL STATION</b><br>\n",
    "        Station: {row['station_name']} <br>\n",
    "        ID: {row['station_id']} <br>\n",
    "        Elevation: {row['elevation']:.0f}m <br>\n",
    "        Departures: {row['departures']/365:.0f}/day <br>\n",
    "        Arrivals: {row['arrivals']/365:.0f}/day <br>\n",
    "        Total Usage: {row['total_usage_daily']:.0f}/day <br>\n",
    "        <b>Net Flux: {row['arrivals']/365 - row['departures']/365:+.1f}/day</b>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add marker\n",
    "        folium.CircleMarker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            radius=get_radius(row['total_usage_daily']),\n",
    "            color='black',\n",
    "            fill=True,\n",
    "            fill_color=get_color(row['net_flux_daily']),\n",
    "            fill_opacity=0.9,  # Slightly higher opacity\n",
    "            weight=3,\n",
    "            popup=folium.Popup(popup_content, max_width=300)\n",
    "        ).add_to(flux_map)\n",
    "\n",
    "# Updated legend to include critical stations\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; bottom: 50px; left: 50px; width: 175px; height: 170px; \n",
    "            background-color:white; border:2px solid grey; z-index:9999; \n",
    "            font-size:12px; padding: 8px\">\n",
    "<b>Net Flux</b><br>\n",
    "<span style=\"color:#d73027\">●</span> Heavy Export<br>\n",
    "<span style=\"color:#fc8d59\">●</span> Light Export<br>\n",
    "<span style=\"color:gray\">●</span> Balanced<br>\n",
    "<span style=\"color:yellowgreen\">●</span> Light Import<br>\n",
    "<span style=\"color:#1a9850\">●</span> Heavy Import<br>\n",
    "<hr style=\"margin: 5px 0;\">\n",
    "<b>⚫</b> = Top 10 critical station\n",
    "</div>\n",
    "'''\n",
    "\n",
    "flux_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "flux_map.save('../outputs/oslo_flux_map.html')\n",
    "flux_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31067358",
   "metadata": {},
   "source": [
    "### 3.5.4 Summary: Geographic imbalace\n",
    "\n",
    "The interactive map above shows the geographic pattern of the imbalanced flow of bikes in the bike sharing system.  \n",
    "\n",
    "**Clear Spatial Patterns:**\n",
    "- **Northern/Outer areas** (higher elevation): Dominated by red stations that consistantly export bikes - *bike sources*\n",
    "- **Central/southern areas** (lower elevation): Dominated by green stations that consistantly import bikes - *bike sinks*\n",
    "- **Intermediate elevation areas**: Most stations are balanced (gray), creating a transition zone between exporter and importer areas - *transition zone*\n",
    "\n",
    "**Geographic \"Watershed\":**\n",
    "There is a clear three-zone pattern: a green core of heavy importers, surrounded by gray balanced stations at intermediate elevations, surrounded by red exporter stations at higher elevations. There is a daily flow of bikes from higher elevation down into the city center and lower elevation regions.  \n",
    "\n",
    "**Important Note**: This analysis represents a yearly average across all seasons and times of day. The actual rebalancing challenges may be significantly more pronounced during peak times (rush hours, summer months, weekends)  \n",
    "\n",
    "This visualization demonstrates that bike rebalancing in Oslo is not a random maintenance, but follows a clear geographical pattern. \n",
    "\n",
    "**Answer to Question 2:** Elevation systematically affects station imbalance by creating predictable daily bike flows from higher to lower elevations, with stations above ~35m consistently exporting bikes while those below consistently import them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b7e76",
   "metadata": {},
   "source": [
    "### 3.6 Which Stations Require the Most Urgent Daily Rebalancing?\n",
    "Now that we've seen how elevation causes imbalances, let's identify the specific stations that create the most critical challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 heavist importer and exporter stations\n",
    "print(\"TOP 10 EXPORTER STATIONS (Need Daily Restocking)\")\n",
    "print(\"=\"*70)\n",
    "exporters_display = top_exporters[['station_name', 'elevation', 'net_flux_daily', 'total_usage_daily']].copy()\n",
    "exporters_display.columns = ['Station', 'Elevation [m]', 'Bikes Lost Daily', 'Total Daily Usage']\n",
    "exporters_display['Bikes Lost Daily'] = exporters_display['Bikes Lost Daily'].round(1).abs()\n",
    "exporters_display['Total Daily Usage'] = exporters_display['Total Daily Usage'].round(1)\n",
    "print(exporters_display.to_string(index=False))\n",
    "print(f\"\\nTotal daily restocking need: {top_exporters['net_flux_daily'].abs().sum():.0f} bikes\")\n",
    "print(f\"Average elevation: {top_exporters['elevation'].mean():.1f}m\")\n",
    "\n",
    "print(\"\\nTOP 10 IMPORTER STATIONS (Need Daily Removal)\")\n",
    "print(\"=\"*70)\n",
    "importers_display = top_importers[['station_name', 'elevation', 'net_flux_daily', 'total_usage_daily']].copy()\n",
    "importers_display.columns = ['Station', 'Elevation [m]', 'Bikes Gained Daily', 'Total Daily Usage']\n",
    "importers_display['Bikes Gained Daily'] = importers_display['Bikes Gained Daily'].round(1)\n",
    "importers_display['Total Daily Usage'] = importers_display['Total Daily Usage'].round(1)\n",
    "print(importers_display.to_string(index=False))\n",
    "print(f\"\\nTotal daily removal need: {top_importers['net_flux_daily'].abs().sum():.0f} bikes\")\n",
    "print(f\"Average elevation: {top_importers['elevation'].mean():.1f}m\")\n",
    "\n",
    "# Impact summary\n",
    "total_critical_flux = abs(top_exporters['net_flux_daily'].sum()) + top_importers['net_flux_daily'].sum()\n",
    "pct_of_stations = 20 / len(stations) * 100\n",
    "\n",
    "print(f\"\"\"\n",
    "OPERATIONAL IMPACT:\n",
    "- These 20 stations ({pct_of_stations:.1f}% of network) require moving ~{total_critical_flux:.0f} bikes daily\n",
    "- Elevation difference between critical exporters and importers: {top_exporters['elevation'].mean() - top_importers['elevation'].mean():.0f}m\n",
    "- This represents the minimum daily rebalancing operation just to maintain these 20 stations. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0a8e8",
   "metadata": {},
   "source": [
    "### 3.6 Summary: Topography's Impact on Oslo's Bike Sharing System\n",
    "\n",
    "Our topographical analysis reveals that Oslo's terrain creates fundamental operational challenges:\n",
    "\n",
    "**Key Finding 1: Strong Downhill Preference**\n",
    "- Cyclists are 53% more likely to choose downhill routes (59.5% vs 38.8% of trips)\n",
    "- Downhill trips cover 68% more total distance and 38% more ride time\n",
    "- This creates a system-wide \"gravity bias\" with a mean gradient of -0.44%\n",
    "\n",
    "**Key Finding 2: Elevation-Driven Station Imbalances**\n",
    "- Strong negative correlation (-0.61) between elevation and daily net flux\n",
    "- Critical elevation threshold at ~35m separates bike exporters from importers\n",
    "- Geographic pattern: red (exporter) periphery → gray (balanced) middle → green (importer) core\n",
    "\n",
    "**Key Finding 3: Concentrated Rebalancing Needs**\n",
    "- Top 10 exporters (avg 54m elevation) lose 75 bikes daily combined\n",
    "- Top 10 importers (avg 17m elevation) gain 92 bikes daily combined  \n",
    "- Just 7.5% of stations drive the majority of rebalancing requirements\n",
    "\n",
    "**Operational Implications:**\n",
    "\n",
    "This analysis proves that Oslo's bike rebalancing isn't random maintenance but a predictable daily battle against gravity. The system experiences a continuous \"downhill tide\" requiring strategic intervention:\n",
    "\n",
    "1. **Predictable Patterns**: Rebalancing routes can be optimized based on elevation zones\n",
    "2. **Resource Allocation**: Focus on the 20 critical stations for maximum impact\n",
    "3. **Capacity Planning**: Low-elevation stations need more docks, high-elevation stations need more bikes\n",
    "4. **Pricing Strategy**: Consider incentives for uphill trips to naturally counteract gravity\n",
    "\n",
    "The topographical analysis has revealed WHERE bikes flow. Next, we'll examine the network structure to understand HOW bikes move through the system and which routes are most critical for connectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1a284",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Network Structure Analysis\n",
    "Now that we've established that Oslo's topography creates a predictable bike flow from highter to lower elevations, we now examine *how* bikes move through the city. While elevation tells us the direction of the flow, this analysis will reveal the pathways and most ciritical destinations.  \n",
    "  \n",
    "Network analysis treates the bike sharing system as a complex web of interconnected stations, where each trip creates a weighted \"link\" between locations. This approach allows us to understand which stations serve as bike magnets, which routes form the main arteries of travel, and how the system can be split into different functional zones. \n",
    "  \n",
    "Key questions we'll answer:  \n",
    "1. Which stations are most important in the network?\n",
    "2. What are the most important pathways for bike travel?\n",
    "3. How is the bike network organized across Oslo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e555c",
   "metadata": {},
   "source": [
    "### 3.1 Building the Network Graph\n",
    "We start by defining our network graph where stations are nodes and trips create weighted edges between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create directional graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add stations as nodes to graph\n",
    "for _, station in stations.iterrows():\n",
    "    G.add_node(station['station_id'],\n",
    "               name=station['station_name'],\n",
    "               lat=station['lat'],\n",
    "               lon=station['lon'],\n",
    "               elevation=station['elevation'])\n",
    "\n",
    "# Add trips between stations as edges, with frequency of route as weight\n",
    "trip_counts = trips.groupby(['start_station_id', 'end_station_id']).size().reset_index(name='weight')\n",
    "trip_counts = trip_counts.sort_values('weight', ascending=False)#.head(100)\n",
    "\n",
    "for _, trip in trip_counts.iterrows():\n",
    "    G.add_edge(trip['start_station_id'],\n",
    "               trip['end_station_id'],\n",
    "               weight=trip['weight'])\n",
    "\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d4ba3",
   "metadata": {},
   "source": [
    "### 3.2 Which stations are most important to the network?\n",
    "To understand station importance, we calculate several network centrality metrics:  \n",
    "- **PageRank**: Identifies stations that are well-connected to other well-connected stations (\"hubs\"). This metric correlates very well with total station usage.\n",
    "- **Degree Centrality**: Counts how many direct connections a station has. Has a large plateau, since most stations are connected to most other stations over the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906bb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "pagerank = nx.pagerank(G, weight='weight')\n",
    "degree_centrality = dict(G.degree())  # Number of unique connections\n",
    "\n",
    "# Write to stations table\n",
    "station_flux['pagerank'] = station_flux['station_id'].map(pagerank)\n",
    "station_flux['degree_centrality'] = station_flux['station_id'].map(degree_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top n stations\n",
    "n = 10\n",
    "top_pagerank_stations = station_flux.nlargest(n, 'pagerank')\n",
    "top_centrality_stations = station_flux.nlargest(n, 'degree_centrality')\n",
    "print(\"TOP 10 MOST IMPORTANT STATIONS (by PageRank)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (idx, station) in enumerate(top_pagerank_stations.iterrows(), 1):\n",
    "    print(f\"{i:2d}. {station['station_name']}\")\n",
    "    print(f\"    PageRank: {station['pagerank']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33014cae",
   "metadata": {},
   "source": [
    "### 3.3 What are the most critical pathways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all edges with their weights (trip counts)\n",
    "all_edges = [(start, end, data['weight']) for start, end, data in G.edges(data=True)]\n",
    "\n",
    "# Sort by weight (trip count) descending\n",
    "popular_routes = sorted(all_edges, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Convert to readable format\n",
    "top_routes = []\n",
    "for start, end, weight in popular_routes[:20]:  # Top 20\n",
    "    route_info = {\n",
    "        'from': G.nodes[start]['name'],\n",
    "        'to': G.nodes[end]['name'],\n",
    "        'trip_count': weight,\n",
    "        'from_elevation': G.nodes[start]['elevation'],\n",
    "        'to_elevation': G.nodes[end]['elevation'],\n",
    "        'gradient': 'downhill' if G.nodes[end]['elevation'] < G.nodes[start]['elevation'] else 'uphill'\n",
    "    }\n",
    "    top_routes.append(route_info)\n",
    "\n",
    "# Display as DataFrame\n",
    "routes_df = pd.DataFrame(top_routes)\n",
    "print(\"TOP 15 MOST POPULAR CONNECTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, (idx, route) in enumerate(routes_df.head(15).iterrows(), 1):\n",
    "    print(f\"{i:2d}. {route['from']} ↔ {route['to']}\")\n",
    "    print(f\"    {route['trip_count']:,} trips\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c74a6",
   "metadata": {},
   "source": [
    "### 3.4 Network Zones: Core vs. Feeder System\n",
    "Our network analysis reveals a two'zone structure that explains how Oslo's bike stystem actually works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize network in Folium\n",
    "n_edges = 800\n",
    "\n",
    "network_map = folium.Map(location=oslo_coordinates, zoom_start=zoom)#, tiles='CartoDB positron')\n",
    "\n",
    "# Add edges to map\n",
    "top_edges = sorted(\n",
    "    G.edges(data=True),\n",
    "    key=lambda x: x[2]['weight'],\n",
    "    reverse=True\n",
    "    )[:n_edges]\n",
    "\n",
    "# Compute weights for scaling\n",
    "weights = [w['weight'] for _, _, w in top_edges]\n",
    "min_weight, max_weight = min(weights), max(weights)\n",
    "\n",
    "import branca.colormap as cm\n",
    "from branca.element import Element\n",
    "colormap = cm.LinearColormap(['blue', 'darkblue', 'navy'],\n",
    "                              vmin=min_weight, vmax=max_weight)\n",
    "\n",
    "\n",
    "def scale(weight, val_min, val_max, scale_min, scale_max):\n",
    "    return np.interp(\n",
    "        weight,\n",
    "        (val_min, val_max),\n",
    "        (scale_min, scale_max))\n",
    "\n",
    "    \n",
    "for e1, e2, data in top_edges:\n",
    "    lat1, lon1 = G.nodes[e1]['lat'], G.nodes[e1]['lon']\n",
    "    lat2, lon2 = G.nodes[e2]['lat'], G.nodes[e2]['lon']\n",
    "    thickness = scale(data['weight'], min_weight, max_weight, 1, 26)\n",
    "\n",
    "    folium.PolyLine(\n",
    "        locations=[[lat1, lon1], [lat2, lon2]],\n",
    "        weight=thickness,\n",
    "        opacity=scale(data['weight'], min_weight, max_weight, 0.2, 0.3),\n",
    "        color=colormap(data['weight']),#'blue',\n",
    "        dash_array='5, 5' if thickness < 2 else None\n",
    "        \n",
    "    ).add_to(network_map)\n",
    "\n",
    "\n",
    "# Add nodes to map\n",
    "for node, data in G.nodes(data=True):\n",
    "    popup_content =  f\"\"\"\n",
    "    Station: {data['name']} <br>\n",
    "    Elevation: {data['elevation']:.0f}m <br>\n",
    "    \"\"\"\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[data['lat'], data['lon']],\n",
    "        color='black',\n",
    "        radius=2,\n",
    "        fill=True,\n",
    "        fill_opacity=0.3,\n",
    "        popup=folium.Popup(popup_content, max_width=300)\n",
    "    ).add_to(network_map)\n",
    "\n",
    "\n",
    "# Visualize top hubs\n",
    "top_nodes = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:21]\n",
    "\n",
    "for node, score in top_nodes:\n",
    "    lat, lon = G.nodes[node]['lat'], G.nodes[node]['lon']\n",
    "    name, elevation = G.nodes[node]['name'], G.nodes[node]['elevation']\n",
    "    size = scale(score, min(pagerank.values()), max(pagerank.values()), 3, 10)\n",
    "\n",
    "    popup_content =  f\"\"\"\n",
    "    Station: {name} <br>\n",
    "    Elevation: {elevation:.0f}m <br>\n",
    "    \"\"\"\n",
    "    marker = folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=size,\n",
    "        color='#DAA520',\n",
    "        fill=True,\n",
    "        fill_opacity=0.8,\n",
    "        popup=folium.Popup(popup_content, max_width=300),\n",
    "    ).add_to(network_map)\n",
    "\n",
    "    folium.Tooltip(\n",
    "        name,\n",
    "        permanent=True,  # Always visible\n",
    "        # sticky=True,\n",
    "        direction='top',  # Position: 'top', 'bottom', 'left', 'right'\n",
    "        # offset=[0, -10]  # Fine-tune position\n",
    "        class_name='transparent-label',\n",
    "    ).add_to(marker)\n",
    "\n",
    "    transparent_css = \"\"\"\n",
    "    <style>\n",
    "    .transparent-label {\n",
    "        background-color: #DAA520 !important;  /* Light white background */\n",
    "        color: black !important;\n",
    "        border: black !important;\n",
    "        box-shadow: black !important;\n",
    "        font-size: 12px;\n",
    "        padding: 1px 3px;\n",
    "        border-radius: 4px;\n",
    "        font-weight: 600;\n",
    "    }\n",
    "\n",
    "    /* Kill the tooltip arrow */\n",
    "    .transparent-label:before,\n",
    "    .transparent-label:after {\n",
    "        border: none !important;\n",
    "        background: transparent !important;\n",
    "        box-shadow: none !important;\n",
    "        content: none !important;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\"\n",
    "    network_map.get_root().html.add_child(Element(transparent_css))\n",
    "network_map.save('../outputs/oslo_network_map.html')\n",
    "\n",
    "network_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f777c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Money plot: Combine network map and importer/exporter map\n",
    "# Oslo Bike Network: Core vs Feeder Stations\n",
    "\n",
    "n_edges = 600\n",
    "network_flux_map = folium.Map(location=oslo_coordinates, zoom_start=zoom, tiles='CartoDB positron')\n",
    "\n",
    "top_edges = sorted(\n",
    "    G.edges(data=True),\n",
    "    key=lambda x: x[2]['weight'],\n",
    "    reverse=True,\n",
    ")[:n_edges]\n",
    "\n",
    "\n",
    "# Function for scaling valiables\n",
    "def scale(weight, val_min, val_max, scale_min, scale_max):\n",
    "    return np.interp(\n",
    "        weight,\n",
    "        (val_min, val_max),\n",
    "        (scale_min, scale_max)\n",
    "    )\n",
    "\n",
    "# Plot network\n",
    "for start, end, data in top_edges:\n",
    "    lat1, lon1 = G.nodes[start]['lat'], G.nodes[start]['lon']\n",
    "    lat2, lon2 = G.nodes[end]['lat'], G.nodes[end]['lon']\n",
    "    weight = data['weight']\n",
    "    thickness = scale(data['weight'], min_weight, max_weight, 1, 8)\n",
    "\n",
    "    # Thickness and opacity \n",
    "    thickness = 0.5 + (weight / max_weight) * 10\n",
    "    opacity = 0.2 + (weight / max_weight) * 0.3\n",
    "\n",
    "    folium.PolyLine(\n",
    "        locations=[[lat1, lon1], [lat2, lon2]],\n",
    "        weight=thickness,\n",
    "        opacity=opacity,\n",
    "        color='darkblue',\n",
    "    ).add_to(network_flux_map)\n",
    "\n",
    "\n",
    "\n",
    "# Prepare station list\n",
    "# station_flux['pagerank'] = station_flux['station_id'].map(pagerank)\n",
    "\n",
    "# Classify stations\n",
    "def classify_station(net_flux_daily):\n",
    "    if net_flux_daily > 2:\n",
    "        return 'heavy_importer'\n",
    "    elif net_flux_daily > 0.5:\n",
    "        return 'light_importer'\n",
    "    elif net_flux_daily < -2:\n",
    "        return 'heavy_exporter'\n",
    "    elif net_flux_daily < -0.5:\n",
    "        return 'light_exporter'\n",
    "    else:\n",
    "        return 'balanced'\n",
    "    \n",
    "station_flux['station_type'] = station_flux['net_flux_daily'].apply(classify_station)\n",
    "\n",
    "# Find top stations for labelling\n",
    "top_pagerank = station_flux.nlargest(24, 'pagerank')['station_id'].tolist()\n",
    "top_exporters = station_flux.nsmallest(10, 'net_flux_daily')['station_id'].tolist()\n",
    "top_importers = station_flux.nlargest(10, 'net_flux_daily')['station_id'].tolist()\n",
    "\n",
    "stations_to_label = set(top_pagerank + top_exporters + top_importers)\n",
    "\n",
    "# Color mapping\n",
    "color_map = {\n",
    "    'heavy_exporter': '#d73027',\n",
    "    'light_exporter': '#fc8d59',\n",
    "    'balanced': '#ffffbf',\n",
    "    'light_importer': '#91cf60',\n",
    "    'heavy_importer': '#1a9850',\n",
    "}\n",
    "\n",
    "label_css_template = \"\"\"\n",
    "<style>\n",
    ".label-{unique_id} {{\n",
    "    background-color: rgba(255, 255, 255, 0.9);\n",
    "    color: black;\n",
    "    border: 2px solid {label_color};\n",
    "    box-shadow: 2px 2px 2px rgba(0,0,0,0.3);\n",
    "    font-size: 12px;\n",
    "    padding: 1px 3px;\n",
    "    border-radius: 4px;\n",
    "    font-weight: 600;\n",
    "}}\n",
    "\n",
    "/* Kill the tooltip arrow */\n",
    ".label-{unique_id}:before,\n",
    ".label-{unique_id}:after {{\n",
    "    border: none !important;\n",
    "    background: transparent !important;\n",
    "    box-shadow: none !important;\n",
    "    content: none !important;\n",
    "}}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "def get_radius(total_usage):\n",
    "    # Normalize usage\n",
    "    return np.interp(total_usage,\n",
    "                     (station_flux['total_usage_daily'].min(), station_flux['total_usage_daily'].max()),\n",
    "                     (3, 17))\n",
    "\n",
    "for _, station in station_flux.iterrows():\n",
    "    marker_size = get_radius(station['total_usage_daily'])\n",
    "\n",
    "    # Check if station is top exporter or importer\n",
    "    is_top_exporter = station['station_id'] in top_exporters\n",
    "    is_top_importer = station['station_id'] in top_importers\n",
    "\n",
    "    # Define border style for top stations\n",
    "    if is_top_exporter or is_top_importer:\n",
    "        border_weight = 3\n",
    "        border_color = 'black'\n",
    "    else:\n",
    "        border_weight = 1\n",
    "        border_color='darkgray'\n",
    "\n",
    "    # Station color\n",
    "    fill_color = color_map[station['station_type']]\n",
    "\n",
    "    # Create popup\n",
    "    popup_content = f\"\"\"\n",
    "        <b>{station['station_name']}</b><br>\n",
    "        Type: {station['station_type'].replace('_', ' ').title()}<br>\n",
    "        Net Flux: {station['net_flux_daily']:+.1f} bikes/day<br>\n",
    "        Total Usage: {station['total_usage_daily']:.0f} trips/day<br>\n",
    "        Elevation: {station['elevation']:.0f}m\n",
    "    \"\"\"\n",
    "\n",
    "    # Draw station marker\n",
    "    marker = folium.CircleMarker(\n",
    "        location=[station['lat'], station['lon']],\n",
    "        radius=marker_size,\n",
    "        color=border_color,\n",
    "        weight=border_weight,\n",
    "        fillColor=fill_color,\n",
    "        fill=True,\n",
    "        fillOpacity=0.8,\n",
    "        popup=folium.Popup(popup_content, max_width=300)\n",
    "    ).add_to(network_flux_map)\n",
    "\n",
    "    # Add label to important stations\n",
    "    if station['station_id'] in stations_to_label:\n",
    "        if 'exporter' in station['station_type']:\n",
    "            label_color = '#d73027'\n",
    "        elif 'importer' in station['station_type']:\n",
    "            label_color = '#1a9850'\n",
    "        else:\n",
    "            label_color = 'black'\n",
    "\n",
    "        # In your loop, for each station:\n",
    "        unique_id = f\"station_{station['station_id']}\"  # Create unique class name\n",
    "        label_css = label_css_template.format(\n",
    "            unique_id=unique_id,\n",
    "            label_color=label_color\n",
    "        )\n",
    "\n",
    "        # Add the CSS for this specific label\n",
    "        network_flux_map.get_root().html.add_child(folium.Element(label_css))\n",
    "\n",
    "        # Create the tooltip with the unique class\n",
    "        folium.Tooltip(\n",
    "            station['station_name'],\n",
    "            permanent=True,\n",
    "            direction='top',\n",
    "            offset=(0, -marker_size+4),\n",
    "            class_name=f'label-{unique_id}',\n",
    "        ).add_to(marker)\n",
    "\n",
    "# Add legend\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "            bottom: 50px; left: 50px; width: 200px;\n",
    "            background-color: white; border: 2px solid grey;\n",
    "            z-index: 9999; font-size: 11px; padding: 10px\">\n",
    "    <b>Oslo Bike Network Analysis</b><br><br>\n",
    "    <b>Station Types:</b><br>\n",
    "    <span style=\"color: #d73027;\">●</span> Heavy Exporter (>2 bikes/day)<br>\n",
    "    <span style=\"color: #fc8d59;\">●</span> Light Exporter<br>\n",
    "    <span style=\"color: #ffffbf;\">●</span> Balanced (±0.5 bikes/day)<br>\n",
    "    <span style=\"color: #91cf60;\">●</span> Light Importer<br>\n",
    "    <span style=\"color: #1a9850;\">●</span> Heavy Importer (>2 bikes/day)<br>\n",
    "    <br>\n",
    "    <b>Visual Elements:</b><br>\n",
    "    • Size = Total daily usage<br>\n",
    "    • Thick border = Top 5 exporter/importer<br>\n",
    "    • Blue lines = Trip frequency<br>\n",
    "    • Labels = Top stations by PageRank<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ Top 5 exporters/importers\n",
    "</div>\n",
    "'''\n",
    "network_flux_map.get_root().html.add_child(folium.Element(legend_html)) \n",
    "\n",
    "# Add title\n",
    "title_html = '''\n",
    "<div style=\"position: fixed; \n",
    "            top: 10px; left: 50%; transform: translateX(-50%);\n",
    "            background-color: white; border: 2px solid grey;\n",
    "            z-index: 9999; font-size: 16px; font-weight: bold;\n",
    "            text-align: center; padding: 8px 15px;\n",
    "            border-radius: 5px;\">\n",
    "    Oslo Bike Network: Core vs Feeder Stations\n",
    "</div>\n",
    "'''\n",
    "network_flux_map.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "network_flux_map.save('../outputs/network_flux_map.html')\n",
    "network_flux_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c80bde4",
   "metadata": {},
   "source": [
    "The network can be split into two distinct areas:  \n",
    "  \n",
    "**The core network (dense central area)**  \n",
    "- High traffic density with many connections\n",
    "- Net bike importers (accumulate bikes throughout the day)\n",
    "- Short frequent trips between nearby stations\n",
    "- High intra-city circulation  \n",
    "  \n",
    "This dense network serves daily urban activites, such as shopping, errands, meetings and so on. Bikes circulate actively within this zone as people move between neighborhoods.  \n",
    "  \n",
    "**The feeder network (peripheral stations)**\n",
    "- Lower traffic density, fewer connections\n",
    "- Net bike exporters (lose bikes throughout the day)\n",
    "- More isolated from each other\n",
    "  \n",
    "These stations act as \"park and ride\" points for communters. People living in elevated residential areas use bikes for one-way trips into the city center, then rely on other transport to return home. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef110bc",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Temporal Analysis\n",
    "Having identified Oslo's dual-zone network structure (central importers vs. peripheral feeders), we now examine **when** these patterns emerge throught the day.  \n",
    "  \n",
    "This analysis will show how the gravitational flow we discovered earlier plays out hour by hour. This is critical information to plan when trucks have to go out and restock stations or remove bikes from fully stocked ones so that users can park their bikes.  \n",
    "  \n",
    "**Key questions to answer:**  \n",
    "1. When do the peripheral stations feed the central ones?  \n",
    "2. How do different station types behave throughout the day?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe167758",
   "metadata": {},
   "source": [
    "### 4.1 Data preparation: timezone correction\n",
    "Before analyzing temporal patterns, we need to fix an issue with the time stap of the dataset:  \n",
    "  \n",
    "The original dataset shows a an unusual rush hour pattern with peaks at 4-7 and 13-16, clearly outside of normal commuting hours. In addition, trips are outside of the offical opening hours of the bike sharing system, which is from 5 in the morning until 1 o'clock at night.  \n",
    "  \n",
    "**Problem**: The data appears to be in UTC timezone, while Oslo is on CET/CEST (central european time).  \n",
    "**Solution**: We need to convert the timezone to the appropriate one while automatically handling daylight saving time.  \n",
    "**Validation**: After time zone conversion, the bike usage hours align perfectly with Oslo Bysykkel's official operating hours (05:00 - 01:00), and the rush hour patterns appear at normal commuting times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix time stamp\n",
    "trips['started_at'] = pd.to_datetime(trips['started_at']).dt.tz_localize('UTC').dt.tz_convert('Europe/Oslo')\n",
    "trips['ended_at'] = pd.to_datetime(trips['ended_at']).dt.tz_localize('UTC').dt.tz_convert('Europe/Oslo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fcf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hour to trips table\n",
    "trips['hour'] = trips['started_at'].dt.hour\n",
    "\n",
    "plt.hist(trips['hour'], bins=23, color='skyblue', edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "plt.axvspan(7, 9, alpha=0.3, color='gray', label='Morning Rush')\n",
    "plt.axvspan(15, 18, alpha=0.3, color='gray', label='Evening Rush')\n",
    "\n",
    "plt.xticks(range(24))\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Number of Trips')\n",
    "plt.title('System-wide bike usage throughout the day')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea076a8",
   "metadata": {},
   "source": [
    "### 4.2 When do perpheral stations feed the central ones? Extreme station patterns\n",
    "Let's first look at how the daily flux of bikes develops throughout the day. We will start by looking at the most extreme stations, wich are the top most exporting and importing stations.  \n",
    "  \n",
    "To achieve an overview of the daily pattern in the flux of bikes, we need to group the dataset by 'hour of day' and then count the hourly arrivals and departures. This will give us the average flux behaviour over the entire year, smoothing out any seasonal variations such as winter and summmer or weekends and week days, retaining only variations caused by the time of day.  \n",
    "  \n",
    "#### 4.2.1 Top exporters and importers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hourly flux for each station\n",
    "hourly_arrivals = trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Get top n exporters and importers\n",
    "n = 5\n",
    "top_importers = station_flux.nlargest(n, 'net_flux_daily')\n",
    "top_exporters = station_flux.nsmallest(n, 'net_flux_daily')\n",
    "\n",
    "importer_stations = top_importers['station_id'].tolist()\n",
    "exporter_stations = top_exporters['station_id'].tolist()\n",
    "\n",
    "# Plot top exporters and importers\n",
    "plt.figure()\n",
    "# Plot exporters\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    # color=plt.cm.rainbow(0.6 + 0.4 * (i / n))\n",
    "    plt.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "    \n",
    "# Plot importers\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    # color=plt.cm.rainbow(0.6 + 0.4 * (i / n))\n",
    "    plt.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "    \n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "plt.xticks(range(24))\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "plt.title('Extreme Stations: Top Exporters vs. Top Importers')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/imbalanced_stations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375166be",
   "metadata": {},
   "source": [
    "**Key findings**:  \n",
    "  \n",
    "**Exporter station behaviour (blue lines - feeder network)**:  \n",
    "- **Consistent daily export**: All exporter stations remain predominantly negative throughout the day, confirming that bike mainly flow one-way.  \n",
    "- **Extended morning rush (05-09)**  \n",
    "- **Notable exceptions reveal local patterns:**\n",
    "    - **Lindern (Ullevål Hospital)**: Brief import spikes at 06-07 and two dramatic export spikes; one at 15:00 (likely hospital day shift ending) and another at 22:00 (evening shift ending).  \n",
    "    - **BI Nydalen**: Brief import spike at 07-08, probably students and employees arriving at the BI campus. \n",
    "- **No evening return flow**: Confirms that people don't bike back uphill, they use other means of transportation.  \n",
    "  \n",
    "**Importer station behavior (red lines - core network)**:  \n",
    "- **Massive morning influx (07-09)**: All downtown stations show dramatic positive spikes, whith peakes reaching 6+ bikes per hour net inflow.\n",
    "- **Sustained high import levels throughout the day**.\n",
    "- **Divergent afternoon patterns (14-17)**:  \n",
    "    - **Oslo S and Aker Brygge:** Import fluxes spike again, likely due to their roles as major transport hub and place for leasure activities.  \n",
    "    - **Other core stations**: Show more variable patterns, with some even breifly exporting bikes.  \n",
    "- **Evening activities:**  \n",
    "    - **Torggata emerges as top evening importer:** This area seves as destination for evening entertainment, dining and drinks. People bike there after work for social activities. \n",
    "  \n",
    "**Note on temporal variation**: These patterns represent the system behaviour averaged across the entire year. Individual patterns may vary significantly based on seasonal effects (summer/winter), weather conditions (temperature, rain) and day of week (weekend or weekday). Future analys sections will explore these variations in detail. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f61c3",
   "metadata": {},
   "source": [
    "#### 4.2.2 Balanced stations\n",
    "Let's now turn our attention to bike stations at intermediate elevations where the bike flow is more balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1193f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top balanced stations\n",
    "balanced_stations = station_flux[\n",
    "    (station_flux['net_flux'].abs() < 500) & # Small imbalance\n",
    "    (station_flux['total_usage'] > 5000)     # High usage\n",
    "].nlargest(n,'total_usage')\n",
    "\n",
    "# Plot top balanced stations\n",
    "plt.figure()\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    plt.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "    \n",
    "# Add rush hour shading\n",
    "plt.axvspan(6, 9, alpha=0.1, color='gray', label='Morning Rush')\n",
    "plt.axvspan(14.5, 17.5, alpha=0.1, color='gray', label='Afternoon Rush')\n",
    "    \n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "plt.xticks(range(24))\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "plt.title('Balanced Stations: Line Crosses Zero Throughout the Day')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/balanced_stations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc19f6a",
   "metadata": {},
   "source": [
    "**Key findings:**  \n",
    "**Zero-crossing behaviour:**  \n",
    "- Lines cross the `y=0` axis, indicating a two-way flow.\n",
    "No persistent directional bias. Bikes flow both in and out throughout the day.  \n",
    "  \n",
    "**Clear temporal patterns**:\n",
    "- **Morning outtlow (06-09):** These stations show negative spikes, suggesting people leave these areas for work.  \n",
    "- **Afternoon influx (15-18):** As opposed to importer and exporter stations, here there is a clear sign that commuters actually return home by bike, which causes the large influx spike in the afternoon.  \n",
    "- **Alexander Kiellands Plass** shows extreme pattern: Dramatic morning exports (-7 bikes/hour) followed by strong afternoon import (6+ bikes/hour). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2c14b7",
   "metadata": {},
   "source": [
    "### 4.3 Weekday vs. weekend patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde28c2",
   "metadata": {},
   "source": [
    "#### 4.3.1 Trip count and mean duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "trips['weekday'] = trips['started_at'].dt.day_name()\n",
    "\n",
    "weekday_stats = trips.groupby('weekday').size() / 52\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "colors = {\n",
    "    'Monday': 'steelblue',\n",
    "    'Tuesday': 'steelblue', \n",
    "    'Wednesday': 'steelblue', \n",
    "    'Thursday': 'steelblue', \n",
    "    'Friday': 'steelblue', \n",
    "    'Saturday': 'lightsteelblue', \n",
    "    'Sunday': 'lightsteelblue'}\n",
    "\n",
    "bars = plt.bar(day_order, [weekday_stats[day] for day in day_order],\n",
    "               color=[colors[day] for day in day_order],\n",
    "            edgecolor='black', linewidth=0.5, alpha=0.8)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    x = bar.get_x()\n",
    "    width = bar.get_width()\n",
    "    plt.text(x+width/2., height+50, f'{height:.0f}', ha='center',\n",
    "             va='bottom', fontsize=10)\n",
    "\n",
    "plt.title(\"Average daily bike usage: weekdays dominate\")\n",
    "plt.xlabel('Day of week')\n",
    "plt.ylabel('Average trips per day')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekly_usage_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "weekday_stats = trips.groupby('weekday').mean() / 60\n",
    "\n",
    "bars = plt.bar(day_order, [weekday_stats['duration'][day] for day in day_order],\n",
    "               color=[colors[day] for day in day_order],\n",
    "            edgecolor='black', linewidth=0.5, alpha=0.8)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    x = bar.get_x()\n",
    "    width = bar.get_width()\n",
    "    plt.text(x+width/2., height+0.2, f'{height:.0f}', ha='center',\n",
    "             va='bottom', fontsize=10)\n",
    "    \n",
    "plt.title('Average daily trip duration: weekend trips longer')\n",
    "plt.xlabel('Day of week')\n",
    "plt.ylabel('Average daily trip duration [min]')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekly_usage_duration.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e49577",
   "metadata": {},
   "source": [
    "#### 4.3.2 Flux analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfceb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_trips = trips[trips['weekday'].isin(['Saturday', 'Sunday'])]\n",
    "weekday_trips = trips[~trips['weekday'].isin(['Saturday', 'Sunday'])]\n",
    "\n",
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# WEEKDAY PLOT (Left)\n",
    "# Calculate hourly flux for weekdays\n",
    "hourly_arrivals = weekday_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekday_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekday subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers on weekday subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Weekdays: strong commuter patterns')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([-3, 7])\n",
    "\n",
    "\n",
    "# WEEKEND PLOT (Right)\n",
    "# Calculate hourly flux for weekends\n",
    "hourly_arrivals = weekend_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekend_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekend subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers on weekend subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Weekends: gentler leisure patterns')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekday_vs_weekend.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# WEEKDAY PLOT (Left)\n",
    "# Calculate hourly flux for weekdays\n",
    "hourly_arrivals = weekday_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekday_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekday subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Weekdays: strong commuter patterns')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([-8, 6])\n",
    "\n",
    "\n",
    "# WEEKEND PLOT (Right)\n",
    "# Calculate hourly flux for weekends\n",
    "hourly_arrivals = weekend_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekend_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/365\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekend subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "\n",
    "\n",
    "ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Weekends: gentler leisure patterns')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekday_vs_weekend_balanced.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0019b",
   "metadata": {},
   "source": [
    "#### 4.3.3 Total usage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# WEEKDAY PLOT (Left)\n",
    "# Calculate hourly total usage for weekdays\n",
    "hourly_arrivals = weekday_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekday_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_total_usage = (hourly_arrivals + hourly_departures)/365\n",
    "hourly_total_usage = hourly_total_usage.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekday subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers on weekday subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "# ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Weekdays: strong commuter patterns')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "# ax1.set_ylim([-3, 7])\n",
    "\n",
    "\n",
    "# WEEKEND PLOT (Right)\n",
    "# Calculate hourly total usage for weekends\n",
    "hourly_arrivals = weekend_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekend_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_total_usage = (hourly_arrivals + hourly_departures)/365\n",
    "hourly_total_usage = hourly_total_usage.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekend subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers on weekend subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "# ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Weekends: gentler leisure patterns')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekday_vs_weekend_total_usage.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f52212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# WEEKDAY PLOT (Left)\n",
    "# Calculate hourly total usage for weekdays\n",
    "hourly_arrivals = weekday_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekday_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_total_usage = (hourly_arrivals + hourly_departures)/365\n",
    "hourly_total_usage = hourly_total_usage.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekday subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Weekdays: strong commuter patterns')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "# ax1.set_ylim([-8, 6])\n",
    "\n",
    "\n",
    "# WEEKEND PLOT (Right)\n",
    "# Calculate hourly total usage for weekends\n",
    "hourly_arrivals = weekend_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = weekend_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_total_usage = (hourly_arrivals + hourly_departures)/365\n",
    "hourly_total_usage = hourly_total_usage.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters on weekend subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_total_usage.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "\n",
    "\n",
    "# ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Weekends: gentler leisure patterns')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/weekday_vs_weekend_total_usage_balanced.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c4ea51",
   "metadata": {},
   "source": [
    "These colors are difficult to tell apart. find a better solution. Add different dashes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c02758",
   "metadata": {},
   "source": [
    "### 4.4 Summer vs. year-round patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3357cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['month'] = trips['started_at'].dt.month\n",
    "summer_trips = trips[trips['month'].isin([6, 7, 8])]\n",
    "nonsummer_trips = trips[~trips['month'].isin([6, 7, 8])]\n",
    "\n",
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# SUMMER PLOT (Left)\n",
    "# Calculate hourly flux for summer\n",
    "hourly_arrivals = summer_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = summer_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/90\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters in summer subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers in summer subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Summer')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([-6, 12])\n",
    "\n",
    "\n",
    "# REST OF YEAR PLOT (Right)\n",
    "# Calculate hourly flux for rest of year\n",
    "hourly_arrivals = nonsummer_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = nonsummer_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/270\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot exporters rest of year subplot\n",
    "for i, (_, station) in enumerate(top_exporters.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Blues(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "# Plot importers rest of year subplot\n",
    "for i, (_, station) in enumerate(top_importers.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Reds(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='s', label=station['station_name'])\n",
    "\n",
    "ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Rest of year')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/summer_vs_rest_of_year.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# SUMMER PLOT (Left)\n",
    "# Calculate hourly flux for weekdays\n",
    "hourly_arrivals = summer_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = summer_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/90\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot balanced stations in summer subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax1.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax1.set_xticks(range(24))\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Daily Net Flux (Arrivals - Departures)')\n",
    "ax1.set_title('Summer')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([-12, 9])\n",
    "\n",
    "\n",
    "# REST OF YEAR PLOT (Right)\n",
    "# Calculate hourly flux for rest of year\n",
    "hourly_arrivals = nonsummer_trips.groupby(['end_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_departures = nonsummer_trips.groupby(['start_station_id', 'hour']).size().unstack(fill_value=0)\n",
    "hourly_net_flux = (hourly_arrivals - hourly_departures)/270\n",
    "hourly_net_flux = hourly_net_flux.reindex(columns=range(24), fill_value=0)\n",
    "\n",
    "# Plot balanced stations for rest of year subplot\n",
    "for i, (_, station) in enumerate(balanced_stations.iterrows()):\n",
    "    station_id = station['station_id']\n",
    "    color = plt.cm.Greens(0.6 + 0.4 * (i / n))\n",
    "    ax2.plot(range(24), hourly_net_flux.loc[station_id], c=color, \n",
    "             linestyle='-', marker='o', label=station['station_name'])\n",
    "\n",
    "\n",
    "\n",
    "ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\n",
    "ax2.set_xticks(range(24))\n",
    "ax2.set_xlabel('Hour of day')\n",
    "ax2.set_title('Rest of year')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add single legend to the right\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/summer_vs_rest_of_year_balanced.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
